<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MYSQL常见问题</title>
    <link href="/my-blog/2024/03/04/MYSQL%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <url>/my-blog/2024/03/04/MYSQL%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h2 id="MYSQL常见问题"><a href="#MYSQL常见问题" class="headerlink" title="MYSQL常见问题"></a>MYSQL常见问题</h2><h4 id="1-MyISAM、InnoDB-搜索引擎的区别"><a href="#1-MyISAM、InnoDB-搜索引擎的区别" class="headerlink" title="1. MyISAM、InnoDB 搜索引擎的区别"></a>1. MyISAM、InnoDB 搜索引擎的区别</h4><ul><li>InnoDB 支持行级别的锁粒度，MyISAM 不支持，只支持表级别的锁粒度。</li><li>MyISAM 不提供事务支持。InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别。</li><li>MyISAM 不支持外键，而 InnoDB 支持。</li><li>MyISAM 不支持 MVCC，而 InnoDB 支持。</li><li>虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。</li><li>MyISAM 不支持数据库异常崩溃后的安全恢复，而 InnoDB 支持。</li><li>InnoDB 的性能比 MyISAM 更强大。</li></ul><h4 id="2-加锁加到数据还是索引"><a href="#2-加锁加到数据还是索引" class="headerlink" title="2. 加锁加到数据还是索引"></a>2. 加锁加到数据还是索引</h4><p><img src="/my-blog/pics/image-20240310183633867.png" alt="image-20240310183633867"></p><h5 id="2-1-mysql锁分类"><a href="#2-1-mysql锁分类" class="headerlink" title="2.1 mysql锁分类"></a>2.1 mysql锁分类</h5><ul><li>按粒度分<strong>表锁</strong>、<strong>行锁</strong>和<strong>页锁</strong>三种，</li></ul><ul><li><p>按类型分**读锁和写锁(都属于悲观锁)**两种。</p></li><li><p>按性能分<strong>乐观锁</strong>、<strong>悲观锁和意向锁</strong>。</p></li></ul><p>其中，MyISAM和MEMORY存储引擎采用的是<strong>表级锁</strong>，而InnoDB存储引擎支持<strong>行级锁和表级锁</strong></p><h5 id="2-2-表锁、行锁、页锁"><a href="#2-2-表锁、行锁、页锁" class="headerlink" title="2.2 表锁、行锁、页锁"></a>2.2 表锁、行锁、页锁</h5><ul><li><p>表锁：每次操作锁住整张表。<strong>开销小，加锁快；不会出现死锁；</strong>锁定粒度大，发生锁冲突的概率最高，并发度最低；一般用在整表数据迁移的场景。 </p></li><li><p>行锁：对表中一行或多行记录进行加锁控制的方式。<strong>开销大，加锁慢；会出现死锁；</strong>锁定粒度最小，发生锁冲突的概率最低，并发度最高。在 MySQL 中，<strong>行锁是基于索引加载的</strong>，即行锁是要加在索引响应的行上。<strong>索引失效时会升级为表锁。</strong></p></li><li><pre><code class="sql">#给locker表中value列添加索引ALTER TABLE locker ADD index idx_value (value);BEGIN;SELECT * FROM locker WHERE value = 2 FOR UPDATE;# value字段添加索引后，这条SQL只会针对value值为2的记录进行加锁，也就是行锁。在事务提交之前，这些行数据将无法被其他事务修改。</code></pre></li><li><p>页锁：只有BDB存储引擎支持页锁，页锁就是在页的粒度上进行锁定，锁定的数据资源比行锁要多，因为一个页中可以有多个行记录。当我们使用页锁的时候，会出现数据浪费的现象，但这样的浪费最多也就是一个页上的数据行。页锁的开销介于表锁和行锁之间，会出现死锁。锁定粒度介于表锁和行锁之间，并发度一般。</p></li></ul><h5 id="2-3-读锁、写锁、意向锁"><a href="#2-3-读锁、写锁、意向锁" class="headerlink" title="2.3 读锁、写锁、意向锁"></a>2.3 读锁、写锁、意向锁</h5><ul><li>读锁（共享锁，S锁（shared））：多个读操作对同一个资源共享同一个锁，多个读操作可以同时进行而不会互相影响。因为读操作并不会改变数据内容，所以多个事务可以共享同一个锁，并行地读取同一个资源，这样可以提高并发效率。</li><li>写锁（排它锁，X锁（exclude））：当两个事务同时对表中某行数据进行更新操作时，若一个事务先到达并给该行加上排它锁，那么另一个事务就不能在该行加任意类型的锁，直到第一个事务释放了该行的锁。因此，排它锁可以确保在同一时间只有一个事务可以对被加锁的资源进行修改操作，从而避免出现数据竞争和不一致问题。</li><li>意向锁（I锁（Intent Lock））：数据库中的一种表级锁，在行级锁的基础上引入的一种概念。意向锁是用于解决多粒度锁定而设计的，可以避免行级锁和表级锁之间的冲突。<ul><li><strong>意向共享锁（IS）</strong>：在一个事务需要对表中某些行加共享锁（S锁）时，事务首先需要获得表的意向共享锁（IS锁）</li><li><strong>意向排他锁（IX）</strong>：指的是在一个事务需要对表中某些行加排它锁（X锁）时，事务首先需要获得表的意向排它锁（IX锁）。</li><li><strong>意向锁简单来说就是添加行锁时，给表添加一个标识表明该表已经存在共享锁或者是排它锁，其他事务需要加锁直接读取该标识判断是否已经存在锁。</strong></li></ul></li></ul><h5 id="2-4-间隙锁、临键锁"><a href="#2-4-间隙锁、临键锁" class="headerlink" title="2.4 间隙锁、临键锁"></a>2.4 间隙锁、临键锁</h5><ul><li><p>间隙锁：间隙锁就是两个值之间的空隙加锁，是Innodb在可重复读隔离级别下为了解决幻读问题而引入的一种锁机制。需注意<strong>间隙锁只会在可重复读隔离级别（REPEATABLE-READ）下才会生效</strong>。</p><ul><li><strong>间隙锁可以锁定一个范围内的所有记录，包括不存在的记录，从而防止其他事务在该范围内插入或修改数据。</strong></li></ul></li><li><p>临键锁（Next-key Locks）是MySQL InnoDB存储引擎实现的一种数据行级别的锁机制，它是<strong>行级锁与间隙锁的组合</strong>，即位于索引记录与索引区间之间的一种排它锁。<br>临键锁主要目的是为了解决幻读问题，能够封锁该条记录相邻两个键之间的空白区域，防止其他事务在这个区域内插入、修改、删除数据。临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁</p></li></ul><h4 id="3-mysql事务隔离"><a href="#3-mysql事务隔离" class="headerlink" title="3. mysql事务隔离"></a>3. mysql事务隔离</h4><ul><li>MySQL事务是指一组数据库操作，这些操作要么全部执行成功，要么全部不执行</li></ul><h5 id="3-1-事务4大特性-ACID"><a href="#3-1-事务4大特性-ACID" class="headerlink" title="3.1 事务4大特性(ACID)"></a>3.1 事务4大特性(ACID)</h5><ul><li><p>原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么全不执行，不会出现部分执行的情况。</p></li><li><p>一致性（Consistency）：执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的。</p></li><li><p>隔离性（Isolation）：并发访问数据库时，事务的执行不会受到其他事务的干扰，即每个事务都应该像独立运行一样。</p></li><li><p>持久性（Durability）：事务一旦提交，其结果就应该永久保存在数据库中，即使系统崩溃也不应该丢失。</p></li></ul><h5 id="3-2-事务隔离级别"><a href="#3-2-事务隔离级别" class="headerlink" title="3.2 事务隔离级别"></a>3.2 事务隔离级别</h5><ul><li><p>读未提交：最低的隔离级别，允许读取尚未提交的数据变更。</p></li><li><p>读已提交：允许读取并发事务已经提交的数据。</p></li><li><p>可重复读：同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改。</p></li><li><p>串行化：最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰。</p></li></ul><table><thead><tr><th>隔离级别</th><th>并发问题</th><th>适用场景</th></tr></thead><tbody><tr><td>读未提交（read-uncommitted）</td><td>可能会导致脏读、幻读或不可重复读</td><td>并发性要求不高</td></tr><tr><td>读已提交（read-committed）</td><td>可能会导致幻读或不可重复读</td><td>并发性要求较高</td></tr><tr><td>可重复读（repeatable-read）</td><td>可能会导致幻读</td><td>数据一致性要求较高</td></tr><tr><td>可串行化（serializable）</td><td>不会产生干扰</td><td>数据一致性要求非常高</td></tr></tbody></table><p>在实际应用中，需要根据具体情况选择合适的隔离级别，平衡数据的一致性和并发性能。例如，在高并发的Web应用程序中，可以选择可重复读隔离级别，以保证数据的一致性和并发性能。</p><ul><li><p>脏读（Dirty Reads）：事务A读取到了事务B已经修改但尚未提交的数据</p></li><li><p>不可重读（Non-Repeatable Reads）：事务A内部的相同查询语句在不同时刻读出的结果不一致</p></li><li><p>幻读（Phantom Reads）：事务A读取到了事务B提交的新增数据</p></li></ul><h4 id="4-索引失效不同场景"><a href="#4-索引失效不同场景" class="headerlink" title="4. 索引失效不同场景"></a>4. 索引失效不同场景</h4><ul><li>索引失效是指在使用索引进行查询时，索引无法发挥作用，导致查询性能下降。常见的导致索引失效的情况有以下几种：<ul><li><strong>不满足索引列顺序</strong>：如果查询条件中的列顺序与索引列的顺序不一致，索引可能无法被使用。例如，一个联合索引（A, B），如果查询条件只包含了B列而没有A列，那么这个索引就无法被利用。</li><li><strong>使用函数或表达式</strong>：当查询条件中对索引列应用了函数、数学运算、类型转换等操作时，索引可能无法被使用。因为索引的创建是基于原始列值的，无法直接使用函数计算后的结果进行索引匹配。</li><li><strong>字符串比较问题</strong>：对于字符串类型的索引列，使用了不符合索引规则的比较方式。</li><li><strong>数据类型不匹配</strong>：当查询条件的数据类型与索引列的数据类型不匹配时，索引可能无法被使用。尤其是在进行隐式数据类型转换、不同字符集的比较或编码问题时，需要特别留意。**</li><li><strong>数据量过小</strong>：当表中的数据量较小时，MySQL可能会选择全表扫描而非使用索引，因为全表扫描的成本较低。这种情况下，索引可能无法发挥作用。</li><li><strong>使用了NOT、&lt;&gt;、OR等非优化的逻辑操作符</strong>：这些逻辑操作符在查询条件中的使用会导致索引失效，因为它们无法充分利用索引的特性。</li></ul></li></ul><h4 id="5-操作日志"><a href="#5-操作日志" class="headerlink" title="5. 操作日志"></a>5. 操作日志</h4><blockquote><p><strong>undo、redo在innoDB存储引擎层面 ；binlog服务层日志</strong></p><ul><li><p>一般来说，引擎层日志主要记录以下信息：</p><p>1） 事务信息：事务开始、提交、回滚等操作的信息。</p><p>2） 修改信息：对存储结构进行的操作，如对数据表的增删改等操作。    </p><p>3）数据页信息：记录数据页的信息和相关的状态，包括数据页的读入、写入和修改等操作。</p><p>4） 锁信息：当前引擎使用的锁信息，它会记录锁定时间、锁定的类型、锁定的范围等。</p><p>5） I/O 操作：记录 I/O 操作的详细信息，如 I/O 耗时、I/O 操作的数据页、I/O 操作的数据块等。</p><p>InnoDB存储引擎则拥有 redo log 和 undo log 两种引擎层日志，用于在事务提交时保证数据的一致性和完整性。</p></li></ul></blockquote><h5 id="5-1-undo-用于撤销与事务相关的修改操作，以保证事务的原子性"><a href="#5-1-undo-用于撤销与事务相关的修改操作，以保证事务的原子性" class="headerlink" title="5.1 undo(用于撤销与事务相关的修改操作，以保证事务的原子性)"></a>5.1 undo(用于撤销与事务相关的修改操作，以保证事务的原子性)</h5><p>undo log（撤销日志）是MySQL在InnoDB存储引擎中记录事务的日志的一种类型，记录了正在执行的每个事务所做的修改操作之前的状态信息，以实现对于事务的回滚。</p><p>undo log 可以提供以下作用：</p><ol><li>支持事务回滚：当事务进行回滚操作时，可以使用 undo log 中的信息回滚到事务开始之前的状态。</li><li>支持 MVCC：多版本并发控制需要对版本的表进行维护，而 undo log 可以保留之前版本的数据，在读同时进行写时不会出现数据的不一致性。</li><li>保证数据的一致性：InnoDB 存储引擎使用 undo log 的方式，可以保证当 MySQL 服务在执行操作期间出现异常时不会在数据上引入不一致性。</li></ol><p><strong>「undo log 的原理：」</strong></p><ol><li>在执行 SQL 语句之前，InnoDB 存储引擎将会为该语句开启一个事务，并为每个修改操作创建一个undo log记录。</li><li>对于 DML（INSERT、UPDATE、DELETE）操作和数据定义操作（DDL SELECT等），InnoDB 在事务开始前就会生成 undo log 记录，记录主键、页编号、旧值、新值等信息，保存在与数据表相对应的 undo segment 中。</li><li>当撤销操作出现时，InnoDB 会通过 undo log 中记录的操作来回滚已经提交的修改操作。</li><li>InnoDB 会为各个数据段的 undo log 创建回收队列，回收完成后释放相关资源，防止数据的大量积累。</li></ol><h5 id="5-2-redo-记录事务过程中的修改操作，以保证事务的安全性"><a href="#5-2-redo-记录事务过程中的修改操作，以保证事务的安全性" class="headerlink" title="5.2 redo  (记录事务过程中的修改操作，以保证事务的安全性)"></a>5.2 redo  (记录事务过程中的修改操作，以保证事务的安全性)</h5><p>redo log（重做日志）是 MySQL 进行数据持久化时，记录的一种日志类型。redo log 记录的是 InnoDB 存储引擎中数据文件的修改操作，用于保证 MySQL 数据库在异常崩溃等情况下的数据一致性。redo log 是 MySQL 中 WAL（Write-Ahead Logging）机制的实现之一。</p><p>redo log 具有以下作用：</p><ul><li>在系统崩溃或重启时恢复数据：redo log 记录了所有更改数据的操作，从而可以使 MySQL 在崩溃的情况下恢复所有未被落盘到磁盘上的更改，确保数据不被破坏且数据一致性得以维护。</li><li>减少随机写磁盘的次数：MySQL 写入磁盘的随机操作非常低效，redo log 机制可以将 MySQL 对于数据修改的写操作集中到一块更高效的地方，从而避免了每次操作都要进行磁盘随机读写的场景，提高性能。</li><li>实现 MySQL 中的多版本并发控制：多个事务操作同一个数据库时，MySQL 通过 redo log 等多种机制来实现事务的 ACID 和 MVCC 特性，保证多个事务之间的并发执行的安全性。</li></ul><p>在 MySQL 数据库中，redo log 使用固定大小的循环缓冲区来实现存储。缓冲区大小可以通过参数进行配置，一旦运行日志满，会新创建一个日志文件，并继续写入操作记录。管理员可以手动启动或停止 redo log 功能来想要的灵活控制。</p><h5 id="5-3-binlog-二进制日志记录了MySQL-Server层执行的所有修改操作"><a href="#5-3-binlog-二进制日志记录了MySQL-Server层执行的所有修改操作" class="headerlink" title="5.3 binlog (二进制日志记录了MySQL Server层执行的所有修改操作)"></a>5.3 binlog (二进制日志<strong>记录了MySQL Server层执行的所有修改操作</strong>)</h5><p>binlog（binary log）是MySQL中用于记录执行修改语句的一种二进制日志。其作用是记录MySQL Server所执行的修改操作（例如对数据表的插入、更新、删除等操作），并以二进制格式进行记录。binlog主要用于MySQL的数据恢复、备份和主从复制等方面。</p><p>binlog的生成和写入是在MySQL Server层完成的。在MySQL Server层，binlog被称为“复制日志”（Replication Log）或“事务日志”（Transaction Log），它记录了MySQL Server层执行的所有修改的操作（以二进制形式存储），而不是记录在底层的存储引擎之中。</p><p>在MySQL的执行过程中，所有的修改操作均被交给MySQL Server处理，并被记录在binlog中。当MySQL执行完所有的修改操作并提交事务之后，binlog会将修改操作写入磁盘中。此时，binlog中记录的修改操作就可以用于数据恢复、备份和主从复制等操作。</p><p>binlog的三种格式</p><ul><li><strong>「Statement格式：」</strong> binlog记录 SQL 语句，也就是 SQL 语句本身被记到 binlog 中。优点是记录量较小，缺点是有些语句不确定性很大，例如：UUID() 函数等，或者执行的随机的函数等，可能不稳定。</li><li><strong>「Row格式：」</strong> 每一行数据的变化被记录在 binlog 里面。优点是可以记录较为精确的修改信息，缺点是记录的数据量较大。</li><li><strong>「Mixed格式：」</strong> Statement 和 Row 格式的混合使用，MySQL 会自行判断采用哪种方式，使得记录 binlog 达到最优方案。</li></ul><p>binlog是MySQL Server中一个非常重要的工具，它对于完整记录和追踪数据库的修改操作以及主从复制等操作具有十分重要的作用。</p><blockquote><p><strong>总结</strong>：</p><ol><li><strong>「保证数据的完整性和一致性」</strong><br>MySQL采用了“redo log”和“undo log”来保证数据操作的ACID特性。</li><li><strong>「数据备份与恢复」</strong><br>MySQL使用binlog作为最重要的日志之一，其用于记录MySQL Server层执行的所有修改操作。当MySQL Server因故障停机或者出现数据错误时，可以通过使用二进制日志进行数据恢复。</li><li><strong>「发现和解决问题」</strong><br>MySQL Server层的各种日志（例如，Slow query log，Error Log）以及InnoDB数据库引擎日志（例如 redo log）可以用来诊断系统问题或质量问题。</li><li><strong>「性能分析和优化」</strong><br>通过访问日志、查询日志以及慢查询日志等日志，可以根据记录的数据分析和优化MySQL Server的性能。</li></ol></blockquote><h4 id="5、死锁排查过程、explain具体信息"><a href="#5、死锁排查过程、explain具体信息" class="headerlink" title="5、死锁排查过程、explain具体信息"></a>5、死锁排查过程、explain具体信息</h4><h5 id="5-1-死锁排查"><a href="#5-1-死锁排查" class="headerlink" title="5.1 死锁排查"></a>5.1 死锁排查</h5><ul><li><p>确定事务隔离级别，检查死锁对应的表索引</p><ul><li>确定隔离级别可以后续方便排查锁；RC是没有间隙、临键锁的；<strong>RC于RR更适合高并发，死锁概率小</strong></li></ul></li><li><p>获取死锁日志:  <code>show engine innodb status</code>，找到死锁的SQL</p></li><li><p>分析事务，一般死锁就是 <code>事务1 持有A获取B；事务2 持有B获取A</code>；explain对应的SQL</p></li><li><p>分析死锁原因（引用一篇死锁分析的文章:happy: <a href="https://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&mid=2650123710&idx=1&sn=4601abda3d87a7d8651db8c6511a47f9&chksm=f36bb09fc41c3989e4eb6a6674279707328a0cdeebcc67e6c2138137530f0c8c446f75a403eb&scene=21#wechat_redirect">一次诡异的线上数据库的死锁问题排查过程</a>）</p><ul><li><p>分析加锁过程非常关键，死锁的发生与否，并不在于事务中有多少条SQL语句，死锁的关键在于：<strong>两个(或以上)的Session加锁的顺序不一致</strong>。</p></li><li><p>确定好索引不同的类型进行分析</p></li><li><blockquote><p>事务在以非主键索引为where条件进行Update的时候，会先对该非主键索引加锁，然后再查询该非主键索引对应的主键索引都有哪些，再对这些主键索引进行加锁。</p></blockquote></li></ul></li></ul><h5 id="5-2-EXPLAIN"><a href="#5-2-EXPLAIN" class="headerlink" title="5.2 EXPLAIN"></a>5.2 EXPLAIN</h5><ul><li>id列：每个select都有一个对应的id号，并且是从1开始自增的</li><li>select_type列：表示查询语句执行的查询操作类型<ul><li>simple：简单select，不包括union与子查询</li><li>primary：复杂查询中最外层查询，比如使用union或</li></ul></li><li>table列：查询所涉及的表名。如果有多个表，将显示多行记录</li><li>partitions列：表分区情况</li><li>type列：查询所使用的访问类型<ul><li>效率从高到低分别为：<strong>system &gt; const &gt; eq_ref &gt; ref</strong> &gt; fulltext &gt; ref_or_null <strong>&gt; range &gt; index &gt; ALL，</strong>一般来说保证range级别，最好能达到ref级别。</li></ul></li><li>possible_keys列：表示在查询中可能使用到某个索引或多个索引；如果没有选择索引，显示NULL</li><li>key列：表示在查询中实际使用的索引，如果没有使用索引，显示NULL。</li><li>key_len列：表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度（主要使用在联合索引）</li><li>ref列：表示将哪个字段或常量和key列所使用的字段进行比较。</li><li>rows列：全表扫描时表示需要扫描表的行数估计值；索引扫描时表示扫描索引的行数估计值；值越小越好（不是结果集中的行数）</li><li>filtered列：表示符合查询条件的数据百分比。可以使用rows * filtered/100计算出与<strong>explain</strong>前一个表进行连接的行数。</li><li>Extra列：SQL执行查询的一些额外信息<ul><li>Using Index：使用非主键索引树就可以查询所需要的数据。一般是覆盖索引，即查询列都包含在辅助索引树叶子节点中，不需要回表查询。</li><li>Using where：不通过索引查询所需要的数据</li><li>Using index condition：表示查询列不被索引覆盖，where 条件中是一个索引范围查找，过滤完索引后回表找到所有符合条件的数据行。</li><li>Using temporary：表示需要使用临时表来处理查询；</li><li>Using filesort：当查询中包含 order by 操作而且无法利用索引完成的排序操作，数据较少时从内存排序，如果数据较多需要在磁盘中排序。    需优化成索引排序。</li><li>Select tables optimized away：使用某些聚合函数（min,max）来访问某个索引值</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>works</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>并发编程</title>
    <link href="/my-blog/2024/03/04/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
    <url>/my-blog/2024/03/04/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="并发编程"><a href="#并发编程" class="headerlink" title="并发编程"></a>并发编程</h2><blockquote><p>革命尚未成功，同志仍需努力！</p></blockquote><h3 id="1-线程和进程"><a href="#1-线程和进程" class="headerlink" title="1. 线程和进程"></a>1. 线程和进程</h3><ul><li>进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。</li><li>线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的<strong>堆</strong>和<strong>方法区</strong>资源，但每个线程有自己的<strong>程序计数器</strong>、<strong>虚拟机栈</strong>和<strong>本地方法栈</strong>，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。</li><li>一个进程中可以有多个线程，多个线程共享进程的<strong>堆</strong>和<strong>方法区 <strong>和元空间资源，但是每个线程有自己的</strong>程序计数器</strong>、<strong>虚拟机栈</strong> 和 <strong>本地方法栈</strong>。</li></ul><p><img src="/my-blog/pics/ace830df-9919-48ca-91b5-60b193f593d2.png" alt="image"></p><h3 id="2-线程的状态"><a href="#2-线程的状态" class="headerlink" title="2. 线程的状态"></a>2. 线程的状态</h3><ul><li><p>NEW: 初始状态，线程被创建出来但没有被调用 <code>start()</code> 。</p></li><li><p>RUNNABLE: 运行状态，线程被调用了 <code>start()</code>等待运行的状态。</p></li><li><p>BLOCKED：阻塞状态，需要等待锁释放。</p></li><li><p>WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。 Object.notify() / Object.notifyAll()</p></li><li><p>TIMED_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。</p></li><li><p>TERMINATED：终止状态，表示该线程已经运行完毕。</p></li></ul><h4 id="2-1-线程的几种机制"><a href="#2-1-线程的几种机制" class="headerlink" title="2.1 线程的几种机制"></a>2.1 线程的几种机制</h4><ul><li><p>**Executor **： Executor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。</p></li><li><p><strong>Daemon</strong>：守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。main() 属于非守护线程。使用 setDaemon() 方法将一个线程设置为守护线程。</p></li><li><p><strong>sleep</strong>：Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒,<strong>不会释放锁</strong>.</p></li><li><p><strong>wait</strong>：wait() 是 Object 的方法，<strong>释放锁</strong>后其它线程进入对象的同步方法执行 notify() 或者 notifyAll() 来唤醒挂起的线程。</p></li><li><p><strong>join</strong>：线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是等待，直到目标线程结束。</p></li><li><p><strong>yield</strong>：对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。</p></li><li><p><strong>interrupt</strong>：通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。</p></li><li><p><strong>shutdown</strong>：调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。</p><blockquote><p> <strong>并发三要素</strong></p><ul><li><p>CPU 增加了缓存，以均衡与内存的速度差异；// 导致 <code>可见性</code>问题</p></li><li><p>操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；// 导致 <code>原子性</code>问题</p></li><li><p>编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致 <code>有序性</code>问题</p></li><li><p><strong>可见性</strong>：一个线程对共享变量的修改，另外一个线程能够立刻看到。</p></li><li><p><strong>原子性</strong>：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p></li><li><p><strong>有序性</strong>：即程序执行的顺序按照代码的先后顺序执行。</p></li><li><blockquote><p><strong>为解决以上问题，java提供关键字、锁等以解决并发问题,保证线程安全</strong></p><ul><li>互斥同步: synchronized 和 ReentrantLock</li><li>非阻塞同步: CAS, AtomicXXXX</li><li>无同步方案: 栈封闭，Thread Local，可重入代码</li></ul></blockquote></li></ul></blockquote><p><img src="/my-blog/pics/java-lock-1.png" alt="img"></p></li></ul><h3 id="3-volatile-关键字"><a href="#3-volatile-关键字" class="headerlink" title="3. volatile 关键字"></a>3. volatile 关键字</h3><ul><li><strong><code>volatile</code> 关键字除了可以保证变量的可见性，还有一个重要的作用就是防止 JVM 的指令重排序。</strong>其修饰的变量是共享且不稳定的，每次使用它都到主存中进行读取。但是不能保证数据的原子性。</li><li>防止指令重排序：<strong>双重校验锁实现对象单例（线程安全）</strong></li></ul><h3 id="4-悲观锁"><a href="#4-悲观锁" class="headerlink" title="4. 悲观锁"></a>4. 悲观锁</h3><ul><li><strong>共享资源每次只给一个线程使用，其它线程阻塞</strong>，用完后再把资源转让给其它线程。</li></ul><h4 id="4-1-synchronized-关键字"><a href="#4-1-synchronized-关键字" class="headerlink" title="4.1 synchronized 关键字"></a>4.1 synchronized 关键字</h4><h5 id="4-1-1-关键点"><a href="#4-1-1-关键点" class="headerlink" title="4.1.1 关键点"></a>4.1.1 关键点</h5><ul><li><p>一把锁只能同时被一个线程获取，没有获得锁的线程只能等待；</p></li><li><p><strong>每个实例</strong>都对应有自己的一把锁(this),不同实例之间互不影响；例外：锁<strong>对象</strong>是*.class以及synchronized修饰的是<strong>static方法</strong>的时候，所有对象公用同一把锁。</p></li><li><p>synchronized修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁</p></li></ul><h5 id="4-1-2-使用方式"><a href="#4-1-2-使用方式" class="headerlink" title="4.1.2 使用方式"></a>4.1.2 使用方式</h5><ul><li>对象锁：包括方法锁(默认锁对象为this,当前实例对象)和同步代码块锁(自己指定锁对象)</li><li>类锁：指synchronize修饰静态的方法或指定锁对象为Class对象</li></ul><h5 id="4-1-3-原理分析"><a href="#4-1-3-原理分析" class="headerlink" title="4.1.3 原理分析"></a>4.1.3 原理分析</h5><p>   monitorenter、monitorexit</p><h5 id="4-1-4-缺陷"><a href="#4-1-4-缺陷" class="headerlink" title="4.1.4 缺陷"></a>4.1.4 缺陷</h5><ul><li><p><code>效率低</code>：锁的释放情况少，只有代码执行完毕或者异常结束才会释放锁；试图获取锁的时候不能设定超时，不能中断一个正在使用锁的线程，相对而言，Lock可以中断和设置超时</p></li><li><p><code>不够灵活</code>：加锁和释放的时机单一，每个锁仅有一个单一的条件(某个对象)，相对而言，读写锁更加灵活</p></li><li><p><code>无法知道是否成功获得锁</code>，相对而言，Lock可以拿到状态，如果成功获取锁，….，如果获取失败，…..</p></li><li><p>在能选择的情况下，既不要用Lock也不要用synchronized关键字，用java.util.concurrent包中的各种各样的类，如果不用该包下的类，在满足业务的情况下，可以使用synchronized关键，因为代码量少，避免出错.</p></li></ul><h4 id="4-2-ReentrantLock"><a href="#4-2-ReentrantLock" class="headerlink" title="4.2 ReentrantLock"></a>4.2 ReentrantLock</h4><h3 id="5-乐观锁"><a href="#5-乐观锁" class="headerlink" title="5. 乐观锁"></a>5. 乐观锁</h3><ul><li>乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。</li></ul><h4 id="5-1-CAS"><a href="#5-1-CAS" class="headerlink" title="5.1 CAS"></a>5.1 CAS</h4><h5 id="5-1-1-关键点"><a href="#5-1-1-关键点" class="headerlink" title="5.1.1 关键点"></a>5.1.1 关键点</h5><ul><li><strong>CAS的全称为Compare-And-Swap，直译就是对比交换</strong>。是一条CPU的原子指令，其作用是让CPU先进行比较两个值是否相等，然后原子地更新某个位置的值，经过调查发现，其实现方式是基于<strong>硬件平台的汇编指令</strong>，就是说CAS是靠硬件实现的，JVM只是封装了汇编调用，那些AtomicInteger类便是使用了这些封装后的接口。</li><li>CAS操作是原子性的，所以多线程并发使用CAS更新数据时，可以不使用锁。JDK中大量使用了CAS来更新数据而防止加锁(synchronized 重量级锁)来保持原子更新。</li></ul><h5 id="5-1-2-问题"><a href="#5-1-2-问题" class="headerlink" title="5.1.2 问题"></a>5.1.2 问题</h5><ul><li><p>ABA问题：一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时则会发现它的值没有发生变化，但是实际上却变化了。</p><blockquote><p>AtomicStampedReference ：stamp版本号</p><p>AtomicMarkableReference ：boolean类型的标记</p></blockquote></li><li><p>循环时间长开销大：自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。</p></li></ul><h5 id="5-1-3-AtomicInteger"><a href="#5-1-3-AtomicInteger" class="headerlink" title="5.1.3 AtomicInteger"></a>5.1.3 AtomicInteger</h5><ul><li> AtomicInteger 底层用的是volatile的变量和CAS来进行更改数据的；volatile保证线程的可见性，多线程并发时，一个线程修改数据，可以保证其它线程立马看到修改后的值；CAS 保证数据更新的原子性。</li></ul><h5 id="5-1-4-Unsafe"><a href="#5-1-4-Unsafe" class="headerlink" title="5.1.4 Unsafe"></a>5.1.4 Unsafe</h5><ul><li>原子类底层由Unsafe实现</li></ul><h3 id="6-ThreadLocal"><a href="#6-ThreadLocal" class="headerlink" title="6. ThreadLocal"></a>6. ThreadLocal</h3><h3 id="7-线程池"><a href="#7-线程池" class="headerlink" title="7. 线程池"></a>7. 线程池</h3><h3 id="8-Future"><a href="#8-Future" class="headerlink" title="8. Future"></a>8. Future</h3><h3 id="9-AbstractQueuedSynchronizer（AQS）"><a href="#9-AbstractQueuedSynchronizer（AQS）" class="headerlink" title="9. AbstractQueuedSynchronizer（AQS）"></a>9. AbstractQueuedSynchronizer（AQS）</h3><ul><li>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即<strong>将暂时获取不到锁的线程加入到队列中</strong>。</li><li>AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。</li><li>状态信息通过procted类型的getState，setState，compareAndSetState进行操作</li></ul><blockquote><p>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。</p></blockquote><h4 id="9-1-AQS-对资源的共享方式"><a href="#9-1-AQS-对资源的共享方式" class="headerlink" title="9.1 AQS 对资源的共享方式"></a>9.1 AQS 对资源的共享方式</h4><p>AQS定义两种资源共享方式</p><ul><li>Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： <ul><li>公平锁：按照线程在队列中的排队顺序，先到者先拿到锁</li><li>非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的</li></ul></li><li>Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。</li></ul><ul><li><p>ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。</p></li><li><p>不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。</p></li></ul><h3 id="10-JUC集合"><a href="#10-JUC集合" class="headerlink" title="10. JUC集合"></a>10. JUC集合</h3><h3 id="11-JUC线程池"><a href="#11-JUC线程池" class="headerlink" title="11. JUC线程池"></a>11. JUC线程池</h3><h3 id="12-JUC工具类"><a href="#12-JUC工具类" class="headerlink" title="12. JUC工具类"></a>12. JUC工具类</h3>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>works</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>REDIS缓存</title>
    <link href="/my-blog/2024/02/29/REDIS%E7%BC%93%E5%AD%98/"/>
    <url>/my-blog/2024/02/29/REDIS%E7%BC%93%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<h2 id="REDIS缓存"><a href="#REDIS缓存" class="headerlink" title="REDIS缓存"></a>REDIS缓存</h2><h3 id="1-基础数据结构"><a href="#1-基础数据结构" class="headerlink" title="1. 基础数据结构"></a>1. 基础数据结构</h3><blockquote><p>Redis的每种对象其实都由<strong>对象结构(redisObject)</strong> 与 <strong>对应编码的数据结构</strong>组合而成，而每种对象类型对应若干编码方式，不同的编码方式所对应的底层数据结构是不同的。</p><p><strong>Redis 必须让每个键都带有类型信息, 使得程序可以检查键的类型, 并为它选择合适的处理方式</strong>，<strong>操作数据类型的命令除了要对键的类型进行检查之外, 还需要根据数据类型的不同编码进行多态处理</strong>；从而引入redisObject 对象：</p><ul><li>基于 redisObject 对象的类型检查.</li><li>基于 redisObject 对象的显式多态函数.</li><li>对 redisObject 进行分配、共享和销毁的机制</li></ul></blockquote><h4 id="1-0-对象结构-redisObject-与-底层数据结构"><a href="#1-0-对象结构-redisObject-与-底层数据结构" class="headerlink" title="1.0 对象结构(redisObject) 与 底层数据结构"></a>1.0 <strong>对象结构(redisObject)</strong> 与 <strong>底层数据结构</strong></h4><h5 id="1-0-1-redisObject数据结构"><a href="#1-0-1-redisObject数据结构" class="headerlink" title="1.0.1 redisObject数据结构"></a>1.0.1 redisObject数据结构</h5><p><img src="/my-blog/pics/db-redis-object-1.png" alt="img"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Redis 对象</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">redisObject</span> &#123;</span><br><br>    <span class="hljs-comment">// 类型</span><br>    <span class="hljs-type">unsigned</span> type:<span class="hljs-number">4</span>;<br><br>    <span class="hljs-comment">// 编码方式</span><br>    <span class="hljs-type">unsigned</span> encoding:<span class="hljs-number">4</span>;<br><br>    <span class="hljs-comment">// LRU - 24位, 记录最末一次访问时间（相对于lru_clock）; 或者 LFU（最少使用的数据：8位频率，16位访问时间）</span><br>    <span class="hljs-type">unsigned</span> lru:LRU_BITS; <span class="hljs-comment">// LRU_BITS: 24</span><br><br>    <span class="hljs-comment">// 引用计数</span><br>    <span class="hljs-type">int</span> refcount;<br><br>    <span class="hljs-comment">// 指向底层数据结构实例</span><br>    <span class="hljs-type">void</span> *ptr;<br><br>&#125; robj;<br></code></pre></td></tr></table></figure><ul><li><p>总结一句话：根据redisObject 的<code>type</code>属性以及<code>encoding </code>属性找到对应的数据结构，而<code>ptr </code>指针就指向quicklist的对象；</p><p><img src="/my-blog/pics/db-redis-object-2-2.png" alt="img"></p></li></ul><h5 id="1-0-2-底层数据结构"><a href="#1-0-2-底层数据结构" class="headerlink" title="1.0.2 底层数据结构"></a>1.0.2 底层数据结构</h5><ul><li><p>SDS：这是一种用于存储二进制数据的一种结构, 具有动态扩容的特点. 其实现位于src/sds.h与src/sds.c中。<code>len</code> 保存了SDS保存字符串的长度；<code>buf[]</code> 数组用来保存字符串的每个元素；<code>alloc</code>分别以uint8, uint16, uint32, uint64表示整个SDS, 除过头部与末尾的\0, 剩余的字节数；<code>flags</code> 始终为一字节, 以低三位标示着头部的类型, 高5位未使用。</p><p><img src="/my-blog/pics/image-20240305165400477.png" alt="image-20240305165400477"></p></li></ul><blockquote><p><strong>为什么不使用C语言字符串实现，而是使用 SDS呢</strong>？</p><ul><li><p> SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)； C 语言是经过遍历计数来实现的，时间复杂度为 O(n)</p></li><li><p><strong>杜绝缓冲区溢出</strong>：C语言拼接字符串时长度不够会溢出； SDS<strong>会先根据记录的 len 属性检查内存空间是否满足需求</strong>后判断是否进行扩容。</p></li><li><p><strong>减少修改字符串的内存重新分配次数</strong>：C语言修改字符串需要重新分配内存，SDS实现了<code>空间预分配</code>和<code>惰性空间释放</code>两种方式</p></li><li><blockquote><p>1、<code>空间预分配</code>：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。</p><p>2、<code>惰性空间释放</code>：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 <code>alloc</code> 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）</p></blockquote></li><li><p><strong>二进制安全</strong></p></li><li><p><strong>兼容部分 C 字符串函数</strong></p></li></ul></blockquote><p><img src="/my-blog/pics/redis-ds-2.png" alt="img"></p><ul><li><p>压缩列表 - ZipList ：特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。</p><p><img src="/my-blog/pics/db-redis-ds-x-6.png" alt="img"></p></li><li><p>快表 - QuickList：它是一种以ziplist为结点的双端链表结构. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。</p></li><li><p>字典/哈希表 - Dict：哈希表</p></li><li><p>整数集 - IntSet：整数集合（intset）是集合类型的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。</p></li><li><p>跳表 - ZSkipList：跳跃表结构在 Redis 中的运用场景只有一个，那就是作为有序列表 (Zset) 的使用。跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这就是跳跃表的长处。跳跃表的缺点就是需要的存储空间比较大，属于利用空间来换取时间的数据结构。</p></li></ul><h4 id="1-1-String字符串"><a href="#1-1-String字符串" class="headerlink" title="1.1 String字符串"></a>1.1 String字符串</h4><ul><li>可以是字符串、整数或浮点数</li><li>对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作；</li></ul><table><thead><tr><th>命令</th><th>简述</th><th>使用</th></tr></thead><tbody><tr><td>GET</td><td>获取存储在给定键中的值</td><td>GET name</td></tr><tr><td>SET</td><td>设置存储在给定键中的值</td><td>SET name value</td></tr><tr><td>DEL</td><td>删除存储在给定键中的值</td><td>DEL name</td></tr><tr><td>INCR</td><td>将键存储的值加1</td><td>INCR key</td></tr><tr><td>DECR</td><td>将键存储的值减1</td><td>DECR key</td></tr><tr><td>INCRBY</td><td>将键存储的值加上整数</td><td>INCRBY key amount</td></tr><tr><td>DECRBY</td><td>将键存储的值减去整数</td><td>DECRBY key amount</td></tr></tbody></table><h4 id="1-2-List列表"><a href="#1-2-List列表" class="headerlink" title="1.2 List列表"></a>1.2 List列表</h4><ul><li>一个链表，链表上的每个节点都包含一个字符串</li><li>对链表的两端进行push和pop操作，读取单个或多个元素；根据值查找或删除元素；</li></ul><ul><li><strong>命令使用</strong></li></ul><table><thead><tr><th>命令</th><th>简述</th><th>使用</th></tr></thead><tbody><tr><td>RPUSH</td><td>将给定值推入到列表右端</td><td>RPUSH key value</td></tr><tr><td>LPUSH</td><td>将给定值推入到列表左端</td><td>LPUSH key value</td></tr><tr><td>RPOP</td><td>从列表的右端弹出一个值，并返回被弹出的值</td><td>RPOP key</td></tr><tr><td>LPOP</td><td>从列表的左端弹出一个值，并返回被弹出的值</td><td>LPOP key</td></tr><tr><td>LRANGE</td><td>获取列表在给定范围上的所有值</td><td>LRANGE key 0 -1</td></tr><tr><td>LINDEX</td><td>通过索引获取列表中的元素。你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。</td><td>LINDEX key index</td></tr><tr><td>LTRIM</td><td>用于对列表进行修剪操作，即保留指定范围内的元素，而删除其他元素</td><td>ltrim mylist 0 9</td></tr><tr><td>BRPOP</td><td>从指定的一个或多个列表中弹出（返回并移除）最后一个元素，客户端将被阻塞直到超时时间到达，或者有新元素被添加到列表中</td><td>BRPOP mylist 1</td></tr></tbody></table><ul><li>使用列表的技巧<ul><li>lpush+lpop=Stack(栈)</li><li>lpush+rpop=Queue（队列）</li><li>lpush+ltrim=Capped Collection（有限集合）</li><li>lpush+brpop=Message Queue（消息队列）</li></ul></li></ul><h4 id="1-3-Set集合"><a href="#1-3-Set集合" class="headerlink" title="1.3 Set集合"></a>1.3 Set集合</h4><ul><li>包含字符串的<strong>无序</strong>集合</li><li>字符串的集合，包含基础的方法有看是否存在添加、获取、删除；还包含计算交集、并集、差集等命令</li></ul><ul><li><strong>命令使用</strong></li></ul><table><thead><tr><th>命令</th><th>简述</th><th>使用</th></tr></thead><tbody><tr><td>SADD</td><td>向集合添加一个或多个成员</td><td>SADD key value</td></tr><tr><td>SCARD</td><td>获取集合的成员数</td><td>SCARD key</td></tr><tr><td>SMEMBERS</td><td>返回集合中的所有成员</td><td>SMEMBERS key member</td></tr><tr><td>SISMEMBER</td><td>判断 member 元素是否是集合 key 的成员</td><td>SISMEMBER key member</td></tr></tbody></table><ul><li>实战场景<ul><li><strong>标签</strong>（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。</li><li><strong>点赞，或点踩，收藏等</strong>，可以放到set中实现</li></ul></li></ul><h4 id="1-4-Zset有序集合"><a href="#1-4-Zset有序集合" class="headerlink" title="1.4 Zset有序集合"></a>1.4 <strong>Zset有序集合</strong></h4><ul><li>和散列一样，用于存储<strong>键值对</strong></li><li>字符串成员与浮点数分数之间的<strong>有序映射</strong>；元素的排列顺序由<strong>分数的大小</strong>决定；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素</li></ul><table><thead><tr><th>命令</th><th>简述</th><th>使用</th></tr></thead><tbody><tr><td>ZADD</td><td>将一个带有给定分值的成员添加到有序集合里面</td><td>ZADD zset-key 178 member1</td></tr><tr><td>ZRANGE</td><td>根据元素在有序集合中所处的位置，从有序集合中获取多个元素</td><td>ZRANGE zset-key 0-1 withccores</td></tr><tr><td>ZREM</td><td>如果给定元素成员存在于有序集合中，那么就移除这个元素</td><td>ZREM zset-key member1</td></tr></tbody></table><ul><li>实战场景<ul><li><strong>排行榜</strong>：有序集合经典使用场景。例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。</li></ul></li></ul><h4 id="1-5-Hash散列"><a href="#1-5-Hash散列" class="headerlink" title="1.5 Hash散列"></a>1.5 <strong>Hash散列</strong></h4><ul><li>包含键值对的<strong>无序散列表</strong></li><li>包含方法有添加、获取、删除单个元素</li></ul><ul><li><strong>命令使用</strong></li></ul><table><thead><tr><th>命令</th><th>简述</th><th>使用</th></tr></thead><tbody><tr><td>HSET</td><td>添加键值对</td><td>HSET hash-key sub-key1 value1</td></tr><tr><td>HGET</td><td>获取指定散列键的值</td><td>HGET hash-key key1</td></tr><tr><td>HGETALL</td><td>获取散列中包含的所有键值对</td><td>HGETALL hash-key</td></tr><tr><td>HDEL</td><td>如果给定键存在于散列中，那么就移除这个键</td><td>HDEL hash-key sub-key1</td></tr></tbody></table><h4 id="1-6-Stream类型"><a href="#1-6-Stream类型" class="headerlink" title="1.6 Stream类型"></a>1.6 Stream类型</h4><p>Stream与Redis现有数据结构比较：</p><table><thead><tr><th>Stream</th><th>List, Pub/Sub, Zset</th></tr></thead><tbody><tr><td>获取元素高效，复杂度为O(logN)</td><td>List获取元素的复杂度为O(N)</td></tr><tr><td>支持offset，每个消息元素有唯一id。不会因为新元素加入或者其他元素淘汰而改变id。</td><td>List没有offset概念，如果有元素被逐出，无法确定最新的元素</td></tr><tr><td>支持消息元素持久化，可以保存到AOF和RDB中</td><td>Pub/Sub不支持持久化消息</td></tr><tr><td>支持消费分组</td><td>Pub/Sub不支持消费分组</td></tr><tr><td>支持ACK（消费确认）</td><td>Pub/Sub不支持</td></tr><tr><td>Stream性能与消费者数量无明显关系</td><td>Pub/Sub性能与客户端数量负相关</td></tr><tr><td>允许按时间线逐出历史数据，支持block，给予radix tree和listpack，内存开销少</td><td>Zset不能重复添加相同元素，不支持逐出和block，内存开销大</td></tr><tr><td>不能从中间删除消息元素</td><td>Zet支持删除任意元素</td></tr></tbody></table><p>:happy:详细介绍：<a href="https://trxu.gitee.io/my-blog/2023/11/01/%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3/">Redis之Stream类型理解</a></p><h4 id="1-7-HyperLogLogs（基数统计）"><a href="#1-7-HyperLogLogs（基数统计）" class="headerlink" title="1.7 HyperLogLogs（基数统计）"></a>1.7 HyperLogLogs（基数统计）</h4><ul><li><p>基数即不重复的元素（理解为数组交集 ），可接受容错</p></li><li><p>这个结构可以非常省内存的去统计各种计数，比如注册 IP 数、每日访问 IP 数、页面实时UV、在线用户数，共同好友数等</p></li><li><p>```bash<br>pfadd key1 a b c d e f g h i    # 创建第一组元素<br>pfcount key1                    # 统计元素的基数数量<br>pfmerge key3 key1 key2            # 合并两组：key1 key2 -&gt; key3 并集</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><br><span class="hljs-comment">#### 1.8 Bitmap （位存储）</span><br><br>* <span class="hljs-keyword">Bitmap </span>即位图数据结构，都是操作二进制位来进行记录，只有<span class="hljs-number">0</span> 和 <span class="hljs-number">1</span> 两个状态。<br><br>* 应用：统计用户信息，活跃，不活跃！ 登录，未登录！ 打卡，不打卡！ **两个状态的，都可以使用 <span class="hljs-keyword">Bitmaps**！</span><br><span class="hljs-keyword"></span><br>  如果存储一年的打卡状态需要多少内存呢？ <span class="hljs-number">365</span> 天 = <span class="hljs-number">365</span> <span class="hljs-keyword">bit </span><span class="hljs-number">1</span>字节 = <span class="hljs-number">8</span>bit <span class="hljs-number">46</span> 个字节左右！<br><br>* ```<span class="hljs-keyword">bash</span><br><span class="hljs-keyword"></span>  setbit sign <span class="hljs-number">3</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># 周二没打卡</span><br>  getbit sign <span class="hljs-number">3</span><br>  <span class="hljs-keyword">bitcount </span>sign <span class="hljs-comment"># 统计这周的打卡记录，就可以看到是否有全勤！</span><br></code></pre></td></tr></table></figure></li></ul><h4 id="1-9-geospatial-地理位置"><a href="#1-9-geospatial-地理位置" class="headerlink" title="1.9 geospatial (地理位置)"></a>1.9 geospatial (地理位置)</h4><ul><li><p>geo底层的实现原理实际上就是<strong>Zset</strong>, 我们可以通过Zset命令来操作geo</p></li><li><p>```</p><h1 id="当坐标位置超出上述指定范围时，该命令将会返回一个错误。"><a href="#当坐标位置超出上述指定范围时，该命令将会返回一个错误。" class="headerlink" title="当坐标位置超出上述指定范围时，该命令将会返回一个错误。"></a>当坐标位置超出上述指定范围时，该命令将会返回一个错误。</h1><p>geoadd china:city 118.76 32.04 manjing 112.55 37.86 taiyuan 123.43 41.80 shenyang</p><h1 id="获取指定的成员的经度和纬度"><a href="#获取指定的成员的经度和纬度" class="headerlink" title="获取指定的成员的经度和纬度"></a>获取指定的成员的经度和纬度</h1><p>geopos china:city taiyuan manjing</p><h1 id="距离"><a href="#距离" class="headerlink" title="距离"></a>距离</h1><p>geodist china:city taiyuan shenyang m<br>geodist china:city taiyuan shenyang km</p><h1 id="附近的人-gt-获得所有附近的人的地址-定位-通过半径来查询"><a href="#附近的人-gt-获得所有附近的人的地址-定位-通过半径来查询" class="headerlink" title="附近的人 ==&gt; 获得所有附近的人的地址, 定位, 通过半径来查询"></a>附近的人 ==&gt; 获得所有附近的人的地址, 定位, 通过半径来查询</h1><h1 id="以-100-30-这个坐标为中心-寻找半径为1000km的城市"><a href="#以-100-30-这个坐标为中心-寻找半径为1000km的城市" class="headerlink" title="以 100,30 这个坐标为中心, 寻找半径为1000km的城市"></a>以 100,30 这个坐标为中心, 寻找半径为1000km的城市</h1><p>georadius china:city 110 30 1000 km</p><h1 id="显示与指定成员一定半径范围内的其他成员-参数与-georadius-一样"><a href="#显示与指定成员一定半径范围内的其他成员-参数与-georadius-一样" class="headerlink" title="显示与指定成员一定半径范围内的其他成员 参数与 georadius 一样"></a>显示与指定成员一定半径范围内的其他成员 参数与 georadius 一样</h1><p>georadiusbymember china:city taiyuan 1000 km</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs stata"><br>  :dagger:城市数据:[GEO](http:<span class="hljs-comment">//www.jsons.cn/lngcode)</span><br>  <br>  +++<br><br>+++<br><br><br><br>### 2. 持久化（RDB和AOF）<br><br>#### 2.1 RDB 持久化<br><br>&gt; ​     RDB 就是 Redis DataBase 的缩写，中文名为快照/内存快照，RDB持久化是把当前进程数据生成快照保存到磁盘上的过程，由于是某一时刻的快照，那么快照中的值要早于或者等于内存中的值。<br><br>##### 2.1.1 触发方式<br><br><span class="hljs-comment">* 手工触发</span><br><span class="hljs-comment">  * **save命令**：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间**阻塞**，线上环境不建议使用</span><br><span class="hljs-comment">  * **bgsave命令**：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短</span><br><span class="hljs-comment">  * 具体流程如下：</span><br><span class="hljs-comment">    * redis客户端执行bgsave命令或者自动触发bgsave命令；</span><br><span class="hljs-comment">    * 主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回；</span><br><span class="hljs-comment">    * 如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作；</span><br><span class="hljs-comment">    * 子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件；</span><br><span class="hljs-comment">    * 同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence下的rdb_*相关选项）。![img](/my-blog/pics/redis-x-rdb-1.png)</span><br><br><span class="hljs-comment">* 自动触发</span><br><span class="hljs-comment">  * redis.conf中配置`save m n`，即在m秒内有n次修改时，自动触发bgsave生成rdb文件；</span><br><span class="hljs-comment">  * 主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点；</span><br><span class="hljs-comment">  * 执行debug reload命令重新加载redis时也会触发bgsave操作；</span><br><span class="hljs-comment">  * 默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作；</span><br><br>##### 2.1.2 redis.<span class="hljs-keyword">conf</span>中配置RDB<br><br><span class="hljs-comment">**快照周期**：内存快照虽然可以通过技术人员手动执行SAVE或BGSAVE命令来进行，但生产环境下多数情况都会设置其周期性执行条件。</span><br><br>- **Redis中默认的周期新设置**<br><br>```bash<br># 周期性执行条件的设置格式为<br><span class="hljs-keyword">save</span> &lt;seconds&gt; &lt;changes&gt;<br><br># 默认的设置为：<br><span class="hljs-keyword">save</span> 900 1<br><span class="hljs-keyword">save</span> 300 10<br><span class="hljs-keyword">save</span> 60 10000<br><br># 以下设置方式为关闭RDB快照功能<br><span class="hljs-keyword">save</span> <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure></li></ul><p>以上三项默认信息设置代表的意义是：</p><ul><li>如果900秒内有1条Key信息发生变化，则进行快照；</li><li>如果300秒内有10条Key信息发生变化，则进行快照；</li><li>如果60秒内有10000条Key信息发生变化，则进行快照。读者可以按照这个规则，根据自己的实际请求压力进行设置调整。</li><li><strong>其它相关配置</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 文件名称</span><br>dbfilename dump.rdb<br><br><span class="hljs-comment"># 文件保存路径</span><br><span class="hljs-built_in">dir</span> /home/work/app/redis/data/<br><br><span class="hljs-comment"># 如果持久化出错，主进程是否停止写入</span><br>stop-writes-on-bgsave-error <span class="hljs-built_in">yes</span><br><br><span class="hljs-comment"># 是否压缩</span><br>rdbcompression <span class="hljs-built_in">yes</span><br><br><span class="hljs-comment"># 导入时是否检查</span><br>rdbchecksum <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><p><code>dbfilename</code>：RDB文件在磁盘上的名称。</p><p><code>dir</code>：RDB文件的存储路径。默认设置为“./”，也就是Redis服务的主目录。</p><p><code>stop-writes-on-bgsave-error</code>：上文提到的在快照进行过程中，主进程照样可以接受客户端的任何写操作的特性，是指在快照操作正常的情况下。如果快照操作出现异常（例如操作系统用户权限不够、磁盘空间写满等等）时，Redis就会禁止写操作。这个特性的主要目的是使运维人员在第一时间就发现Redis的运行错误，并进行解决。一些特定的场景下，您可能需要对这个特性进行配置，这时就可以调整这个参数项。该参数项默认情况下值为yes，如果要关闭这个特性，指定即使出现快照错误Redis一样允许写操作，则可以将该值更改为no。</p><p><code>rdbcompression</code>：该属性将在字符串类型的数据被快照到磁盘文件时，启用LZF压缩算法。Redis官方的建议是请保持该选项设置为yes，因为“it’s almost always a win”。</p><p><code>rdbchecksum</code>：从RDB快照功能的version 5 版本开始，一个64位的CRC冗余校验编码会被放置在RDB文件的末尾，以便对整个RDB文件的完整性进行验证。这个功能大概会多损失10%左右的性能，但获得了更高的数据可靠性。所以如果您的Redis服务需要追求极致的性能，就可以将这个选项设置为no。</p><h5 id="2-1-3-深入理解"><a href="#2-1-3-深入理解" class="headerlink" title="2.1.3 深入理解"></a>2.1.3 深入理解</h5><p>​    <img src="/my-blog/pics/redis-x-aof-42.jpg" alt="img"></p><ul><li><p><strong>由于生产环境中我们为Redis开辟的内存区域都比较大（例如6GB），那么将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢</strong>？</p><ul><li>RDB中的核心思路是Copy-on-Write，来保证在进行快照操作的这段时间，需要压缩写入磁盘上的数据在内存中不会发生变化。在正常的快照操作中，一方面Redis主进程会fork一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应。另一方面这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域。</li><li>举个例子：如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。</li></ul></li><li><p><strong>在进行快照操作的这段时间，如果发生服务崩溃怎么办</strong>？</p><ul><li>很简单，在没有将数据全部写入到磁盘前，这次快照操作都不算成功。如果出现了服务崩溃的情况，将以上一次完整的RDB快照文件作为恢复内存数据的参考。也就是说，在快照操作过程中不能影响上一次的备份数据。Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。</li></ul></li><li><p><strong>可以每秒做一次快照吗</strong>？</p><ul><li>对于快照来说，所谓“连拍”就是指连续地做快照。这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。但是，这其中的快照间隔时间就很关键了。</li><li>如下图所示，我们先在 T0 时刻做了一次快照，然后又在 T0+t 时刻做了一次快照，在这期间，数据块 5 和 9 被修改了。如果在 t 这段时间内，机器宕机了，那么，只能按照 T0 时刻的快照进行恢复。此时，数据块 5 和 9 的修改值因为没有快照记录，就无法恢复了。<img src="/my-blog/pics/redis-x-rdb-2-17097046563823.jpg" alt="img"></li></ul></li></ul><blockquote><p>所以，要想尽可能恢复数据，t 值就要尽可能小，t 越小，就越像“连拍”。那么，t 值可以小到什么程度呢，比如说是不是可以每秒做一次快照？毕竟，每次快照都是由 bgsave 子进程在后台执行，也不会阻塞主线程。这种想法其实是错误的。虽然 bgsave 执行时不阻塞主线程，但是，<strong>如果频繁地执行全量快照，也会带来两方面的开销</strong>：</p><ul><li>一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。</li><li>另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁<strong>阻塞主线程</strong>了。</li></ul><p>那么，有什么其他好方法吗？此时，我们可以做增量快照，就是指做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。这个比较好理解。</p><p>但是它需要我们使用额外的元数据信息去记录哪些数据被修改了，这会带来额外的<strong>空间开销问题</strong>。那么，还有什么方法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢数据呢？且看后文中4.0版本中引入的RDB和AOF的混合方式。</p></blockquote><h5 id="2-1-4-优缺点"><a href="#2-1-4-优缺点" class="headerlink" title="2.1.4 优缺点"></a>2.1.4 优缺点</h5><ul><li><strong>优点</strong><ul><li>RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；</li><li>Redis加载RDB文件恢复数据要远远快于AOF方式；</li></ul></li><li><strong>缺点</strong><ul><li>RDB方式实时性不够，无法做到秒级的持久化；</li><li>每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高；</li><li>RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全；</li><li>版本兼容RDB文件问题；</li></ul></li></ul><blockquote><p>针对RDB不适合实时持久化的问题，Redis提供了<code>AOF</code>持久化方式来解决</p></blockquote><h4 id="2-2-AOF-持久化"><a href="#2-2-AOF-持久化" class="headerlink" title="2.2 AOF 持久化"></a>2.2 AOF 持久化</h4><h5 id="2-2-1-如何实现AOF"><a href="#2-2-1-如何实现AOF" class="headerlink" title="2.2.1 如何实现AOF"></a>2.2.1 如何实现AOF</h5><p>AOF日志记录Redis的每个写命令，步骤分为：命令追加（append）、文件写入（write）和文件同步（sync）。</p><ul><li><p><strong>命令追加</strong> 当AOF持久化功能打开了，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器的 aof_buf 缓冲区。</p></li><li><p><strong>文件写入和同步</strong> 关于何时将 aof_buf 缓冲区的内容写入AOF文件中，Redis提供了三种写回策略：<img src="/my-blog/pics/redis-x-aof-4-17097049595405.jpg" alt="img"></p></li><li><blockquote><p><code>Always</code>，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</p><p><code>Everysec</code>，每秒写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</p><p><code>No</code>，操作系统控制的写回：每个写命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回    磁盘。    </p></blockquote></li></ul><h5 id="2-2-2-redis-conf中配置AOF"><a href="#2-2-2-redis-conf中配置AOF" class="headerlink" title="2.2.2 redis.conf中配置AOF"></a>2.2.2 redis.conf中配置AOF</h5><p>默认情况下，Redis是没有开启AOF的，可以通过配置redis.conf文件来开启AOF持久化，关于AOF的配置如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># appendonly参数开启AOF持久化</span><br>appendonly no<br><br><span class="hljs-comment"># AOF持久化的文件名，默认是appendonly.aof</span><br>appendfilename <span class="hljs-string">&quot;appendonly.aof&quot;</span><br><br><span class="hljs-comment"># AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的</span><br><span class="hljs-built_in">dir</span> ./<br><br><span class="hljs-comment"># 同步策略</span><br><span class="hljs-comment"># appendfsync always</span><br>appendfsync everysec<br><span class="hljs-comment"># appendfsync no</span><br><br><span class="hljs-comment"># aof重写期间是否同步</span><br>no-appendfsync-on-rewrite no<br><br><span class="hljs-comment"># 重写触发配置</span><br>auto-aof-rewrite-percentage 100<br>auto-aof-rewrite-min-size 64mb<br><br><span class="hljs-comment"># 加载aof出错如何处理</span><br>aof-load-truncated <span class="hljs-built_in">yes</span><br><br><span class="hljs-comment"># 文件重写策略</span><br>aof-rewrite-incremental-fsync <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><p>以下是Redis中关于AOF的主要配置信息：</p><p><code>appendonly</code>：默认情况下AOF功能是关闭的，将该选项改为yes以便打开Redis的AOF功能。</p><p><code>appendfilename</code>：这个参数项很好理解了，就是AOF文件的名字。</p><p><code>appendfsync</code>：这个参数项是AOF功能最重要的设置项之一，主要用于设置“真正执行”操作命令向AOF文件中同步的策略。</p><p>什么叫“真正执行”呢？还记得Linux操作系统对磁盘设备的操作方式吗？ 为了保证操作系统中I/O队列的操作效率，应用程序提交的I/O操作请求一般是被放置在linux Page Cache中的，然后再由Linux操作系统中的策略自行决定正在写到磁盘上的时机。而Redis中有一个fsync()函数，可以将Page Cache中待写的数据真正写入到物理设备上，而缺点是频繁调用这个fsync()函数干预操作系统的既定策略，可能导致I/O卡顿的现象频繁 。</p><p>与上节对应，appendfsync参数项可以设置三个值，分别是：always、everysec、no，默认的值为everysec。</p><p><code>no-appendfsync-on-rewrite</code>：always和everysec的设置会使真正的I/O操作高频度的出现，甚至会出现长时间的卡顿情况，这个问题出现在操作系统层面上，所有靠工作在操作系统之上的Redis是没法解决的。为了尽量缓解这个情况，Redis提供了这个设置项，保证在完成fsync函数调用时，不会将这段时间内发生的命令操作放入操作系统的Page Cache（这段时间Redis还在接受客户端的各种写操作命令）。</p><p><code>auto-aof-rewrite-percentage</code>：上文说到在生产环境下，技术人员不可能随时随地使用“BGREWRITEAOF”命令去重写AOF文件。所以更多时候我们需要依靠Redis中对AOF文件的自动重写策略。Redis中对触发自动重写AOF文件的操作提供了两个设置：auto-aof-rewrite-percentage表示如果当前AOF文件的大小超过了上次重写后AOF文件的百分之多少后，就再次开始重写AOF文件。例如该参数值的默认设置值为100，意思就是如果AOF文件的大小超过上次AOF文件重写后的1倍，就启动重写操作。</p><p><code>auto-aof-rewrite-min-size</code>：参考auto-aof-rewrite-percentage选项的介绍，auto-aof-rewrite-min-size设置项表示启动AOF文件重写操作的AOF文件最小大小。如果AOF文件大小低于这个值，则不会触发重写操作。注意，auto-aof-rewrite-percentage和auto-aof-rewrite-min-size只是用来控制Redis中自动对AOF文件进行重写的情况，如果是技术人员手动调用“BGREWRITEAOF”命令，则不受这两个限制条件左右。</p><h5 id="2-2-3-深入理解AOF重写"><a href="#2-2-3-深入理解AOF重写" class="headerlink" title="2.2.3 深入理解AOF重写"></a>2.2.3 深入理解AOF重写</h5><p><img src="/my-blog/pics/redis-x-aof-2.jpg" alt="img"></p><ul><li><p><strong>AOF重写会阻塞吗</strong>？</p><ul><li>AOF重写过程是由后台进程bgrewriteaof来完成的。主线程fork出后台的bgrewriteaof子进程，fork会把主线程的内存拷贝一份给bgrewriteaof子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。所以aof在重写时，在fork进程时是会阻塞住主线程的。</li></ul></li><li><p><strong>AOF日志何时会重写</strong>？</p><ul><li>有两个配置项控制AOF重写的触发：<ul><li><code>auto-aof-rewrite-min-size</code>:表示运行AOF重写时文件的最小大小，默认为64MB。</li><li><code>auto-aof-rewrite-percentage</code>:这个值的计算方式是，当前aof文件大小和上一次重写后aof文件大小的差值，再除以上一次重写后aof文件大小。也就是当前aof文件比上一次重写后aof文件的增量大小，和上一次重写后aof文件大小的比值。</li></ul></li></ul></li><li><p><strong>重写日志时，有新数据写入咋整</strong>？</p><ul><li>重写过程总结为：“一个拷贝，两处日志”。在fork出子进程时的拷贝，以及在重写时，如果有新数据写入，主线程就会将命令记录到两个aof日志内存缓冲区中。如果AOF写回策略配置的是always，则直接将命令写回旧的日志文件，并且保存一份命令至AOF重写缓冲区，这些操作对新的日志文件是不存在影响的。（旧的日志文件：主线程使用的日志文件，新的日志文件：bgrewriteaof进程使用的日志文件）</li><li>而在bgrewriteaof子进程完成会日志文件的重写操作后，会提示主线程已经完成重写操作，主线程会将AOF重写缓冲中的命令追加到新的日志文件后面。这时候在高并发的情况下，AOF重写缓冲区积累可能会很大，这样就会造成阻塞，Redis后来通过Linux管道技术让aof重写期间就能同时进行回放，这样aof重写结束后只需回放少量剩余的数据即可。最后通过修改文件名的方式，保证文件切换的原子性。</li><li>在AOF重写日志期间发生宕机的话，因为日志文件还没切换，所以恢复数据时，用的还是旧的日志文件</li></ul></li><li><p><strong>主线程fork出子进程的是如何复制内存数据的</strong>？</p><ul><li>fork采用操作系统提供的写时复制（copy on write）机制，就是为了避免一次性拷贝大量内存数据给子进程造成阻塞。fork子进程时，子进程时会拷贝父进程的页表，即虚实映射关系（虚拟内存和物理内存的映射索引表），而不会拷贝物理内存。这个拷贝会消耗大量cpu资源，并且拷贝完成前会阻塞主线程，阻塞时间取决于内存中的数据量，数据量越大，则内存页表越大。拷贝完成后，父子进程使用相同的内存地址空间。</li></ul></li><li><p><strong>在重写日志整个过程时，主线程有哪些地方会被阻塞</strong>？</p><ul><li>fork子进程时，需要拷贝虚拟页表，会对主线程阻塞。</li><li>主进程有bigkey写入时，操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。</li><li>子进程重写日志完成后，主进程追加aof重写缓冲区时可能会对主线程阻塞。</li></ul></li><li><p><strong>为什么AOF重写不复用原AOF日志</strong>？</p><ul><li>父子进程写同一个文件会产生竞争问题，影响父进程的性能。</li><li>如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用。</li></ul></li></ul><h4 id="2-3-RDB和AOF混合方式（4-0版本"><a href="#2-3-RDB和AOF混合方式（4-0版本" class="headerlink" title="2.3 RDB和AOF混合方式（4.0版本)"></a>2.3 RDB和AOF混合方式（4.0版本)</h4><ul><li>内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。</li></ul><h4 id="2-4-从持久化中恢复数据"><a href="#2-4-从持久化中恢复数据" class="headerlink" title="2.4 从持久化中恢复数据"></a>2.4 从持久化中恢复数据</h4><p><img src="/my-blog/pics/redis-x-aof-5.png" alt="img"></p><ul><li>redis重启时判断是否开启aof，如果开启了aof，那么就优先加载aof文件；</li><li>如果aof存在，那么就去加载aof文件，加载成功的话redis重启成功，如果aof文件加载失败，那么会打印日志表示启动失败，此时可以去修复aof文件后重新启动；</li><li>若aof文件不存在，那么redis就会转而去加载rdb文件，如果rdb文件不存在，redis直接启动成功；</li><li>如果rdb文件存在就会去加载rdb文件恢复数据，如加载失败则打印日志提示启动失败，如加载成功，那么redis重启成功，且使用rdb文件恢复数据；</li></ul><p>那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。</p><h4 id="2-5-性能与实践"><a href="#2-5-性能与实践" class="headerlink" title="2.5 性能与实践"></a>2.5 性能与实践</h4><p>通过上面的分析，我们都知道RDB的快照、AOF的重写都需要fork，这是一个重量级操作，会对Redis造成阻塞。因此为了不影响Redis主进程响应，我们需要尽可能降低阻塞。</p><ul><li>降低fork的频率，比如可以手动来触发RDB生成快照、与AOF重写；</li><li>控制Redis最大使用内存，防止fork耗时过长；</li><li>使用更牛逼的硬件；</li><li>合理配置Linux的内存分配策略，避免因为物理内存不足导致fork失败。</li></ul><p>在线上我们到底该怎么做？我提供一些自己的实践经验。</p><ul><li>如果Redis中的数据并不是特别敏感或者可以通过其它方式重写生成数据，可以关闭持久化，如果丢失数据可以通过其它途径补回；</li><li>自己制定策略定期检查Redis的情况，然后可以手动触发备份、重写数据；</li><li>单机如果部署多个实例，要防止多个机器同时运行持久化、重写操作，防止出现内存、CPU、IO资源竞争，让持久化变为串行；</li><li>可以加入主从机器，利用一台从机器进行备份处理，其它机器正常响应客户端的命令；</li><li>RDB持久化与AOF持久化可以同时存在，配合使用。</li></ul><h3 id="3-发布与订阅"><a href="#3-发布与订阅" class="headerlink" title="3. 发布与订阅"></a>3. 发布与订阅</h3><h4 id="3-1-简介"><a href="#3-1-简介" class="headerlink" title="3.1 简介"></a>3.1 简介</h4><ul><li>Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。</li><li>两种模式：基于频道(Channel)的发布/订阅；基于模式(pattern)的发布/订阅</li></ul><h4 id="3-2-Channel-（点对点）"><a href="#3-2-Channel-（点对点）" class="headerlink" title="3.2 Channel （点对点）"></a>3.2 Channel （点对点）</h4><p><img src="/my-blog/pics/db-redis-sub-3.svg" alt="img"></p><blockquote><p>底层由字典数据结构实现，可以理解键值对</p><p>publish channel:1 hi  #发布<br>subscribe channel:1   #进入订阅状态</p></blockquote><h4 id="3-3-pattern-（topic）"><a href="#3-3-pattern-（topic）" class="headerlink" title="3.3 pattern  （topic）"></a>3.3 pattern  （topic）</h4><p><img src="/my-blog/pics/db-redis-sub-10.svg" alt="img"></p><p><img src="/my-blog/pics/db-redis-sub-5.svg" alt="img"></p><blockquote><p>底层由链表结构实现</p><p>通配符中?表示1个占位符，*表示任意个占位符(包括0)，?*表示1个以上占位符</p><p><strong>PUBLISH</strong>、<strong>SUBSCRIBE</strong>、<strong>UNSUBSCRIBE</strong>、<strong>PSUBSCRIBE</strong>、<strong>PUNSUBSCRIBE</strong></p><p>使用punsubscribe只能退订通过psubscribe命令订阅的规则，不会影响直接通过subscribe命令订阅的频道；反之亦是。</p><p>严格的字符串匹配，所以<code>punsubscribe *</code> 无法退订<code>c*</code>规则，而是必须使用<code>punsubscribe c*</code>才可以退订</p></blockquote><h3 id="4-事件发布"><a href="#4-事件发布" class="headerlink" title="4. 事件发布"></a>4. 事件发布</h3><h3 id="5-事务"><a href="#5-事务" class="headerlink" title="5. 事务"></a>5. 事务</h3><ul><li><p>Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。</p><p>总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。</p></li></ul><h4 id="5-1-基本命令"><a href="#5-1-基本命令" class="headerlink" title="5.1 基本命令"></a>5.1 基本命令</h4><ul><li>MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。</li><li>EXEC：执行事务中的所有操作命令。</li><li>DISCARD：取消事务，放弃执行事务块中的所有命令。</li><li>WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。</li><li>UNWATCH：取消WATCH对所有key的监视</li></ul><h4 id="5-2-事务出现错误的处理"><a href="#5-2-事务出现错误的处理" class="headerlink" title="5.2 事务出现错误的处理"></a>5.2 事务出现错误的处理</h4><ul><li><strong>语法错误（编译器错误）</strong></li><li><strong>Redis类型错误（运行时错误）</strong></li></ul><h4 id="5-3-CAS操作实现乐观锁"><a href="#5-3-CAS操作实现乐观锁" class="headerlink" title="5.3 CAS操作实现乐观锁"></a>5.3 CAS操作实现乐观锁</h4><ul><li><p>其实就是被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败。</p></li><li><p><strong>watch是如何监视实现的呢</strong>？</p><ul><li><p>Redis使用WATCH命令来决定事务是继续执行还是回滚，那就需要在MULTI之前使用WATCH来监控某些键值对，然后使用MULTI命令来开启事务，执行对数据结构操作的各种命令，此时这些命令入队列。</p></li><li><p>当使用EXEC执行事务时，首先会比对WATCH所监控的键值对，如果没发生改变，它会执行事务队列中的命令，提交事务；如果发生变化，将不会执行事务中的任何命令，同时事务回滚。当然无论是否回滚，Redis都会取消执行事务前的WATCH命令。</p><p><img src="/my-blog/pics/db-redis-trans-2.png" alt="img"></p></li></ul></li></ul><h4 id="5-4-Redis事务执行步骤"><a href="#5-4-Redis事务执行步骤" class="headerlink" title="5.4 Redis事务执行步骤"></a>5.4 Redis事务执行步骤</h4><p>通过上文命令执行，很显然Redis事务执行是三个阶段：</p><ul><li><strong>开启</strong>：以MULTI开始一个事务</li><li><strong>入队</strong>：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面</li><li><strong>执行</strong>：由EXEC命令触发事务</li></ul><p>当一个客户端切换到事务状态之后， 服务器会根据这个客户端发来的不同命令执行不同的操作：</p><ul><li>如果客户端发送的命令为 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令的其中一个， 那么服务器立即执行这个命令。</li><li>与此相反， 如果客户端发送的命令是 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令以外的其他命令， 那么服务器并不立即执行这个命令， 而是将这个命令放入一个事务队列里面， 然后向客户端返回 QUEUED 回复。</li></ul><p><img src="/my-blog/pics/db-redis-trans-1.png" alt="img"></p><h4 id="5-5-为什么-Redis-不支持回滚？"><a href="#5-5-为什么-Redis-不支持回滚？" class="headerlink" title="5.5 为什么 Redis 不支持回滚？"></a>5.5 为什么 Redis 不支持回滚？</h4><ul><li>Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。</li><li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。</li></ul>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>works</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>异步编排使用</title>
    <link href="/my-blog/2024/02/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92/"/>
    <url>/my-blog/2024/02/29/%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92/</url>
    
    <content type="html"><![CDATA[<h2 id="异步编排使用"><a href="#异步编排使用" class="headerlink" title="异步编排使用"></a>异步编排使用</h2><h3 id="1-问题背景"><a href="#1-问题背景" class="headerlink" title="1. 问题背景"></a>1. 问题背景</h3><blockquote><p>复杂业务的代码<strong>串行化</strong>，业务代码存在<strong>依赖</strong>关系，十分消耗时间，可利用CompletableFuture进行<strong>线程异步编排</strong>解决问题。</p></blockquote><h3 id="2-CompletableFuture介绍"><a href="#2-CompletableFuture介绍" class="headerlink" title="2. CompletableFuture介绍"></a>2. CompletableFuture介绍</h3><ul><li><strong>并发执行</strong>多个异步任务，等待它们全部完成或获取其中任意一个的结果。</li><li>对已有的异步任务进行进一步的<strong>转换、组合和操作</strong>。</li><li>异步任务之间存在依赖关系，需要按照一定的顺序进行<strong>串行</strong>执行。</li><li>需要对异步任务的结果进行<strong>异常处理、超时控制或取消操作</strong>。</li></ul><h4 id="2-1-复习线程、线程池的基本概念及使用"><a href="#2-1-复习线程、线程池的基本概念及使用" class="headerlink" title="2.1 复习线程、线程池的基本概念及使用"></a>2.1 复习线程、线程池的基本概念及使用</h4><h5 id="2-1-1-线程实现方式"><a href="#2-1-1-线程实现方式" class="headerlink" title="2.1.1 线程实现方式"></a>2.1.1 线程实现方式</h5><ul><li>继承Thread</li><li>实现Runnable接口</li><li>实现Callable接口+FutureTask（可以拿到返回结果，可以处理异常）</li><li>线程池</li></ul><blockquote><p>Future 是 Java 5 添加的类，用来描述一个异步计算的结果。你可以使用<code>isDone</code>方法检查计 算是否完成，或者使用<code>get</code>阻塞住调用线程，直到计算完成返回结果，你也可以使用<code>cancel</code> 方法停止任务的执行。 虽然<code>Future</code>以及相关使用方法提供了异步执行任务的能力，但是对于结果的获取却是很不 方便，只能通过阻塞或者轮询的方式得到任务的结果。阻塞的方式显然和我们的异步编程的 初衷相违背，轮询的方式又会耗费无谓的CPU资源，而且也不能及时地得到计算结果，为 什么不能用观察者设计模式当计算结果完成及时通知监听者呢？ 很多语言，比如Node.js，采用回调的方式实现异步编程。Java的一些框架，比如Netty，自 己扩展了Java的 <code>Future</code>接口，提供了<code>addListener</code>等多个扩展方法；Googleguava也提供了 通用的扩展Future；Scala也提供了简单易用且功能强大的Future/Promise异步编程模式。 作为正统的Java类库，是不是应该做点什么，加强一下自身库的功能呢？ 在Java8 中, 新增加了一个包含50个方法左右的类:CompletableFuture，提供了非常强大的 Future 的扩展功能，可以帮助我们简化异步编程的复杂性，提供了函数式编程的能力，可以 通过回调的方式处理计算结果，并且提供了转换和组合CompletableFuture的方法。 CompletableFuture 类实现了 Future 接口，所以你还是可以像以前一样通过<code>get</code>方法阻塞或 者轮询的方式获得结果，但是这种方式不推荐使用。 CompletableFuture 和 FutureTask 同属于 Future 接口的实现类，都可以获取线程的执行结果。</p></blockquote><p><img src="/my-blog/pics/image-20240229193115548.png" alt="image-20240229193115548"></p><h5 id="2-1-2-线程池"><a href="#2-1-2-线程池" class="headerlink" title="2.1.2 线程池"></a>2.1.2 线程池</h5><ul><li><p>降低资源的消耗 </p><ul><li>通过重复利用已经创建好的线程降低线程的创建和销毁带来的损耗</li></ul></li><li><p>提高响应速度 </p><ul><li> 因为线程池中的线程数没有超过线程池的最大上限时，有的线程处于等待分配任务 的状态，当任务来时无需创建新的线程就能执行  </li></ul></li><li><p>提高线程的可管理性 </p><ul><li>线程池会根据当前系统特点对池内的线程进行优化处理，减少创建和销毁线程带来 的系统开销。无限的创建和销毁线程不仅消耗系统资源，还降低系统的稳定性，使 用线程池进行统一分配</li></ul></li></ul><p><img src="/my-blog/pics/466603-20200526121457901-233155994.png" alt="img"></p><ul><li><strong>ThreadPoolExecutor原理</strong></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-title function_">ThreadPoolExecutor</span><span class="hljs-params">(<span class="hljs-type">int</span> corePoolSize,</span><br><span class="hljs-params">                          <span class="hljs-type">int</span> maximumPoolSize,</span><br><span class="hljs-params">                          <span class="hljs-type">long</span> keepAliveTime,</span><br><span class="hljs-params">                          TimeUnit unit,</span><br><span class="hljs-params">                          BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="hljs-params">                          ThreadFactory threadFactory,</span><br><span class="hljs-params">                          RejectedExecutionHandler handler)</span> &#123;<br>    <span class="hljs-keyword">if</span> (corePoolSize &lt; <span class="hljs-number">0</span> ||<br>        maximumPoolSize &lt;= <span class="hljs-number">0</span> ||<br>        maximumPoolSize &lt; corePoolSize ||<br>        keepAliveTime &lt; <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">IllegalArgumentException</span>();<br>    <span class="hljs-keyword">if</span> (workQueue == <span class="hljs-literal">null</span> || threadFactory == <span class="hljs-literal">null</span> || handler == <span class="hljs-literal">null</span>)<br>        <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">NullPointerException</span>();<br>    <span class="hljs-built_in">this</span>.acc = System.getSecurityManager() == <span class="hljs-literal">null</span> ?<br>            <span class="hljs-literal">null</span> :<br>            AccessController.getContext();<br>    <span class="hljs-built_in">this</span>.corePoolSize = corePoolSize;<br>    <span class="hljs-built_in">this</span>.maximumPoolSize = maximumPoolSize;<br>    <span class="hljs-built_in">this</span>.workQueue = workQueue;<br>    <span class="hljs-built_in">this</span>.keepAliveTime = unit.toNanos(keepAliveTime);<br>    <span class="hljs-built_in">this</span>.threadFactory = threadFactory;<br>    <span class="hljs-built_in">this</span>.handler = handler;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>线程池创建，准备好corePoolSize数量的核心线程，准备接受任务</li><li>新的任务进来，用corePoolSize准备好的空闲线程执行<ul><li>corePoolSize 满了，就将再进来的任务放入阻塞队列中。空闲的corePoolSize就会自己去阻塞队 列获取任务执行</li><li>阻塞队列满了，就直接开新线程执行，最大只能开到maximumPoolSize指定的数量</li><li>max都执行好了。Max-core数量空闲的线程会在keepAliveTime指定的时间后自 动销毁。最终保持到core大小</li><li>如果线程数开到了max的数量，还有新任务进来，就会使用reject指定的拒绝策 略进行处理</li></ul></li><li>所有的线程创建都是由指定的factory创建的</li></ul><blockquote><p>举例一个线程池 core7； max20 ，queue：50，100并发执行过程：</p><blockquote><p>先有7个能直接得到执行，接下来50个进入队列排队，在多开13个继续执行。现在70个 被安排上了。剩下30个默认拒绝策略。</p></blockquote></blockquote><ul><li><p>常见线程池</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs tex">newCachedThreadPool：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若 无可回收，则新建线程<br>newFixedThreadPool：创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。<br>newScheduledThreadPool：创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。<br>newScheduledThreadPool：创建一个定长线程池，支持定时及周期性任务执行。<br>newSingleThreadExecutor：创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务 按照指定顺序(FIFO,LIFO, 优先级)执行<br></code></pre></td></tr></table></figure></li></ul><h4 id="2-2-创建异步对象"><a href="#2-2-创建异步对象" class="headerlink" title="2.2 创建异步对象"></a>2.2 创建异步对象</h4><ul><li><p>CompletableFuture 提供了四个静态方法来创建一个异步操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">static</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAsync</span><span class="hljs-params">(Runnable runnable)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAsync</span><span class="hljs-params">(Runnablerunnable,Executor executor)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span>&lt;U&gt; CompletableFuture&lt;U&gt; <span class="hljs-title function_">supplyAsync</span><span class="hljs-params">(Supplier&lt;U&gt; supplier)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span>&lt;U&gt; CompletableFuture&lt;U&gt; <span class="hljs-title function_">supplyAsync</span><span class="hljs-params">(Supplier&lt;U&gt; supplier,Executorexecutor)</span><br></code></pre></td></tr></table></figure><p>1）runXxxx都是没有返回结果的，supplyXxx都是可以获取返回结果的</p><p>2）可以传入自定义的线程池，否则就用默认的线程池；</p></li></ul><h4 id="2-3-计算完成时回调方法"><a href="#2-3-计算完成时回调方法" class="headerlink" title="2.3 计算完成时回调方法"></a>2.3 计算完成时回调方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> CompletableFuture&lt;T&gt; <span class="hljs-title function_">whenComplete</span><span class="hljs-params">(BiConsumer&lt;? <span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> Throwable&gt; action)</span>;<br><span class="hljs-keyword">public</span> CompletableFuture&lt;T&gt; <span class="hljs-title function_">whenCompleteAsync</span><span class="hljs-params">(BiConsumer&lt;? <span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> Throwable&gt;action)</span>;<br><span class="hljs-keyword">public</span> CompletableFuture&lt;T&gt; <span class="hljs-title function_">whenCompleteAsync</span><span class="hljs-params">(BiConsumer&lt;? <span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> Throwable&gt;action, Executor executor)</span>;<br><span class="hljs-keyword">public</span> CompletableFuture&lt;T&gt; <span class="hljs-title function_">exceptionally</span><span class="hljs-params">(Function&lt;Throwable,? extends T&gt; fn)</span>;<br></code></pre></td></tr></table></figure><ul><li><p>whenComplete可以处理正常和异常的计算结果，exceptionally处理异常情况。 </p></li><li><p>whenComplete和whenCompleteAsync的区别： </p><ul><li><p>whenComplete：是执行当前任务的线程执行继续执行whenComplete的任务。 </p></li><li><p>whenCompleteAsync：是执行把whenCompleteAsync这个任务继续提交给线程池 来进行执行。 方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其他线程 执行（如果是使用相同的线程池，也可能会被同一个线程选中执行）</p></li></ul></li></ul><h4 id="2-4-handle-方法"><a href="#2-4-handle-方法" class="headerlink" title="2.4 handle 方法"></a>2.4 handle 方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> &lt;U&gt; CompletionStage&lt;U&gt; <span class="hljs-title function_">handle</span><span class="hljs-params">(BiFunction&lt;? <span class="hljs-built_in">super</span> T, Throwable, ? extends U&gt; fn)</span>;<br><span class="hljs-keyword">public</span> &lt;U&gt; CompletionStage&lt;U&gt; <span class="hljs-title function_">handleAsync</span><span class="hljs-params">(BiFunction&lt;? <span class="hljs-built_in">super</span> T, Throwable, ? extends U&gt;fn)</span>;<br><span class="hljs-keyword">public</span> &lt;U&gt; CompletionStage&lt;U&gt; <span class="hljs-title function_">handleAsync</span><span class="hljs-params">(BiFunction&lt;? <span class="hljs-built_in">super</span> T, Throwable, ? extends U&gt;fn,Executor executor)</span>;<br></code></pre></td></tr></table></figure><ul><li>和complete 一样，可对结果做最后的处理（可处理异常），可改变返回值。</li></ul><h4 id="2-5-线程串行化方法"><a href="#2-5-线程串行化方法" class="headerlink" title="2.5 线程串行化方法"></a>2.5 线程串行化方法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="hljs-title function_">thenApply</span><span class="hljs-params">(Function&lt;? <span class="hljs-built_in">super</span> T,? extends U&gt; fn)</span><br><span class="hljs-keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="hljs-title function_">thenApplyAsync</span><span class="hljs-params">(Function&lt;? <span class="hljs-built_in">super</span> T,? extends U&gt; fn)</span><br><span class="hljs-keyword">public</span> &lt;U&gt; CompletableFuture&lt;U&gt; <span class="hljs-title function_">thenApplyAsync</span><span class="hljs-params">(Function&lt;? <span class="hljs-built_in">super</span> T,? extends U&gt; fn,Executor executor)</span><br><span class="hljs-keyword">public</span> CompletionStage&lt;Void&gt; <span class="hljs-title function_">thenAccept</span><span class="hljs-params">(Consumer&lt;? <span class="hljs-built_in">super</span> T&gt; action)</span>;<br><span class="hljs-keyword">public</span> CompletionStage&lt;Void&gt; <span class="hljs-title function_">thenAcceptAsync</span><span class="hljs-params">(Consumer&lt;? <span class="hljs-built_in">super</span> T&gt; action)</span>;<br><span class="hljs-keyword">public</span> CompletionStage&lt;Void&gt; <span class="hljs-title function_">thenAcceptAsync</span><span class="hljs-params">(Consumer&lt;? <span class="hljs-built_in">super</span> T&gt; action,Executorexecutor)</span>;<br><span class="hljs-keyword">public</span> CompletionStage&lt;Void&gt; <span class="hljs-title function_">thenRun</span><span class="hljs-params">(Runnable action)</span>;<br><span class="hljs-keyword">public</span> CompletionStage&lt;Void&gt; <span class="hljs-title function_">thenRunAsync</span><span class="hljs-params">(Runnable action)</span>;<br><span class="hljs-keyword">public</span> CompletionStage&lt;Void&gt; <span class="hljs-title function_">thenRunAsync</span><span class="hljs-params">(Runnable action,Executor executor)</span>;<br></code></pre></td></tr></table></figure><ul><li>thenApply 方法：当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前 任务的返回值。</li><li>thenAccept 方法：消费处理结果。接收任务的处理结果，并消费处理，无返回结果。</li><li>thenRun 方法：只要上面的任务执行完成，就开始执行thenRun，只是处理完任务后，执行 thenRun 的后续操作</li><li>带有Async 默认是异步执行的。同之前。</li><li>Function T：上一个任务返回结果的类型 U：当前任务的返回值类型</li></ul><h4 id="2-6-两任务组合-都要完成"><a href="#2-6-两任务组合-都要完成" class="headerlink" title="2.6 两任务组合- 都要完成"></a>2.6 两任务组合- 都要完成</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span>&lt;U,V&gt;CompletableFuture&lt;V&gt;thenCombine(CompletionStage&lt;? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">U</span>&gt; other,BiFunction&lt;? <span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> U,? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">V</span>&gt;fn);<br><span class="hljs-keyword">public</span> &lt;U,V&gt;CompletableFuture&lt;V&gt;thenCombineAsync(CompletionStage&lt;? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">U</span>&gt; other,BiFunction&lt;? <span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> U,? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">V</span>&gt; fn);<br><span class="hljs-keyword">public</span> &lt;U,V&gt; CompletableFuture&lt;V&gt; <span class="hljs-title function_">thenCombineAsync</span><span class="hljs-params">(CompletionStage&lt;?extends U&gt;other，BiFunction&lt;? <span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> U,? extends V&gt; fn,Executor executor)</span>;<br><span class="hljs-keyword">public</span> &lt;U&gt;CompletableFuture&lt;Void&gt; <span class="hljs-title function_">thenAcceptBoth</span><span class="hljs-params">(CompletionStage&lt;? extends U&gt; other,BiConsumer&lt;?<span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> U&gt; action)</span>;<br><span class="hljs-keyword">public</span> &lt;U&gt; CompletableFuture&lt;Void&gt; <span class="hljs-title function_">thenAcceptBothAsync</span><span class="hljs-params">(CompletionStage&lt;? extends U&gt; other,Biconsumer&lt;? <span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> U&gt; action)</span>;<br><span class="hljs-keyword">public</span> &lt;U&gt;CompletableFuture&lt;Void&gt; <span class="hljs-title function_">thenAcceptBothAsync</span><span class="hljs-params">(CompletionStage&lt;? extends U&gt; other,Biconsumer&lt;?<span class="hljs-built_in">super</span> T,? <span class="hljs-built_in">super</span> U&gt; action,Executor executor)</span>;<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAfterBoth</span><span class="hljs-params">(CompletionStage&lt;?&gt; other,Runnable action)</span>;<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAfterBothAsync</span><span class="hljs-params">(CompletionStage&lt;?&gt; other,Runnable action)</span>;<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAfterBothAsync</span><span class="hljs-params">(Completionstage&lt;?&gt; other;Runnable action,Executorexecutor)</span>;<br></code></pre></td></tr></table></figure><ul><li>两个任务必须都完成，触发该任务。。 </li><li>thenCombine：组合两个future，获取两个future的返回结果，并返回当前任务的返回值</li><li>thenAcceptBoth：组合两个 future，获取两个future 任务的返回结果，然后处理任务，没有 返回值。</li><li>runAfterBoth：组合两个 future，不需要获取future 的结果，只需两个future处理完任务后， 处理该任务。</li></ul><h4 id="2-7-两任务组合-一个完成"><a href="#2-7-两任务组合-一个完成" class="headerlink" title="2.7 两任务组合- 一个完成"></a>2.7 两任务组合- 一个完成</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span>&lt;U&gt;CompletableFuture&lt;U&gt;applyToEither(CompletionStage&lt;? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt; other,Function&lt;? <span class="hljs-built_in">super</span> T,U&gt;fn);<br><span class="hljs-keyword">public</span>&lt;U&gt;CompletableFuture&lt;U&gt;applyToEitherAsync(CompletionStage&lt;?<span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt;other，Function&lt;?<span class="hljs-built_in">super</span> T，U&gt; fn);<br><span class="hljs-keyword">public</span>&lt;U&gt;CompletableFuture&lt;U&gt;applyToEitherAsync(CompletionStage&lt;?<span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt;other,Function&lt;? <span class="hljs-built_in">super</span> T,U&gt; fn,Executor executor);<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt;acceptEither(CompletionStage&lt;?<span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt;other,Consumer&lt;？ <span class="hljs-built_in">super</span> T&gt;action);<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt;acceptEitherAsync(CompletionStage&lt;?<span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt;other,Consumer&lt;? <span class="hljs-built_in">super</span> T&gt;action);<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt;acceptEitherAsync(CompletionStage&lt;? <span class="hljs-keyword">extends</span> <span class="hljs-title class_">T</span>&gt; other,Consumer&lt;? <span class="hljs-built_in">super</span> T&gt; action,Executor executor):<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt;runAfterEither(CompletionStage&lt;?&gt;other,Runnable action);<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt; <span class="hljs-title function_">runAfterEitherAsync</span><span class="hljs-params">(CompletionStage&lt;?&gt; other,Runnable action)</span>;<br><span class="hljs-keyword">public</span> CompletableFuture&lt;Void&gt;runAfterEitherAsync(CompletionStage&lt;?&gt;other,Runnable action,Executor executor);<br></code></pre></td></tr></table></figure><ul><li>当两个任务中，任意一个future任务完成的时候，执行任务。 </li><li>applyToEither：两个任务有一个执行完成，获取它的返回值，处理任务并有新的返回值。 </li><li>acceptEither：两个任务有一个执行完成，获取它的返回值，处理任务，没有新的返回值。 </li><li>runAfterEither：两个任务有一个执行完成，不需要获取future的结果，处理任务，也没有返 回值。</li></ul><h4 id="2-8-多任务组合"><a href="#2-8-多任务组合" class="headerlink" title="2.8 多任务组合"></a>2.8 多任务组合</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> staticCompletableFuture&lt;Void&gt;allof(CompletableFuture&lt;?&gt;...cfs);<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> CompletableFuture&lt;Object&gt; <span class="hljs-title function_">anyof</span><span class="hljs-params">(CompletableFuture&lt;?&gt;...cfs)</span>;<br></code></pre></td></tr></table></figure><ul><li>allOf：等待所有任务完成 </li><li>anyOf：只要有一个任务完成</li></ul><h3 id="3-示例"><a href="#3-示例" class="headerlink" title="3. 示例"></a>3. 示例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> OrderConfirmVo <span class="hljs-title function_">confirmOrder</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> ExecutionException, InterruptedException &#123;<br><br>     <span class="hljs-comment">//构建OrderConfirmVo</span><br>     <span class="hljs-type">OrderConfirmVo</span> <span class="hljs-variable">confirmVo</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">OrderConfirmVo</span>();<br><br>     <span class="hljs-comment">//获取当前用户登录的信息</span><br>     <span class="hljs-type">MemberResponseVo</span> <span class="hljs-variable">memberResponseVo</span> <span class="hljs-operator">=</span> LoginUserInterceptor.loginUser.get();<br><br>     <span class="hljs-comment">//TODO :获取当前线程请求头信息(解决Feign异步调用丢失请求头问题)</span><br>     <span class="hljs-type">RequestAttributes</span> <span class="hljs-variable">requestAttributes</span> <span class="hljs-operator">=</span> RequestContextHolder.getRequestAttributes();<br><br>     <span class="hljs-comment">//开启第一个异步任务</span><br>     CompletableFuture&lt;Void&gt; addressFuture = CompletableFuture.runAsync(() -&gt; &#123;<br><br>          <span class="hljs-comment">//每一个线程都来共享之前的请求数据</span><br>          RequestContextHolder.setRequestAttributes(requestAttributes);<br><br>          <span class="hljs-comment">//1、远程查询所有的收获地址列表</span><br>          List&lt;MemberAddressVo&gt; address = memberFeignService.getAddress(memberResponseVo.getId());<br>          confirmVo.setMemberAddressVos(address);<br>     &#125;, threadPoolExecutor);<br><br>     <span class="hljs-comment">//开启第二个异步任务</span><br>     CompletableFuture&lt;Void&gt; cartInfoFuture = CompletableFuture.runAsync(() -&gt; &#123;<br><br>          <span class="hljs-comment">//每一个线程都来共享之前的请求数据</span><br>          RequestContextHolder.setRequestAttributes(requestAttributes);<br><br>          <span class="hljs-comment">//2、远程查询购物车所有选中的购物项</span><br>          List&lt;OrderItemVo&gt; currentCartItems = cartFeignService.getCurrentCartItems();<br>          confirmVo.setItems(currentCartItems);<br>          <span class="hljs-comment">//feign在远程调用之前要构造请求，调用很多的拦截器</span><br>     &#125;, threadPoolExecutor).thenRunAsync(() -&gt; &#123;<br>          List&lt;OrderItemVo&gt; items = confirmVo.getItems();<br>          <span class="hljs-comment">//获取全部商品的id</span><br>          List&lt;Long&gt; skuIds = items.stream()<br>                  .map((itemVo -&gt; itemVo.getSkuId()))<br>                  .collect(Collectors.toList());<br><br>          <span class="hljs-comment">//远程查询商品库存信息</span><br>          <span class="hljs-type">R</span> <span class="hljs-variable">skuHasStock</span> <span class="hljs-operator">=</span> wmsFeignService.getSkuHasStock(skuIds);<br>          List&lt;SkuStockVo&gt; skuStockVos = skuHasStock.getData(<span class="hljs-string">&quot;data&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">TypeReference</span>&lt;List&lt;SkuStockVo&gt;&gt;() &#123;&#125;);<br><br>          <span class="hljs-keyword">if</span> (skuStockVos != <span class="hljs-literal">null</span> &amp;&amp; skuStockVos.size() &gt; <span class="hljs-number">0</span>) &#123;<br>               <span class="hljs-comment">//将skuStockVos集合转换为map</span><br>               Map&lt;Long, Boolean&gt; skuHasStockMap = skuStockVos.stream().collect(Collectors.toMap(SkuStockVo::getSkuId, SkuStockVo::getHasStock));<br>               confirmVo.setStocks(skuHasStockMap);<br>          &#125;<br>     &#125;,threadPoolExecutor);<br><br>     <span class="hljs-comment">//3、查询用户积分</span><br>     <span class="hljs-type">Integer</span> <span class="hljs-variable">integration</span> <span class="hljs-operator">=</span> memberResponseVo.getIntegration();<br>     confirmVo.setIntegration(integration);<br><br>     <span class="hljs-comment">//4、价格数据自动计算</span><br><br>     <span class="hljs-comment">//TODO 5、防重令牌(防止表单重复提交)</span><br>     <span class="hljs-comment">//为用户设置一个token，三十分钟过期时间（存在redis）</span><br>     <span class="hljs-type">String</span> <span class="hljs-variable">token</span> <span class="hljs-operator">=</span> UUID.randomUUID().toString().replace(<span class="hljs-string">&quot;-&quot;</span>, <span class="hljs-string">&quot;&quot;</span>);<br>     redisTemplate.opsForValue().set(USER_ORDER_TOKEN_PREFIX+memberResponseVo.getId(),token,<span class="hljs-number">30</span>, TimeUnit.MINUTES);<br>     confirmVo.setOrderToken(token);<br><br><br>     CompletableFuture.allOf(addressFuture,cartInfoFuture).get();<br><br>     <span class="hljs-keyword">return</span> confirmVo;<br>&#125;<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>works</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SSL错误</title>
    <link href="/my-blog/2024/02/20/ssl%E9%94%99%E8%AF%AF%E6%8E%92%E6%9F%A5/"/>
    <url>/my-blog/2024/02/20/ssl%E9%94%99%E8%AF%AF%E6%8E%92%E6%9F%A5/</url>
    
    <content type="html"><![CDATA[<h4 id="SSL报错-02"><a href="#SSL报错-02" class="headerlink" title="SSL报错 02"></a>SSL报错 02</h4><p>错误信息代码：Caused by: java.lang.NoSuchMethodError: sun.security.ssl.CipherSuite._jr$ig$keyExchange(Ljava/lang/Object;)Lsun/security/ssl/CipherSuite$KeyExchange;</p><p>百度上没有正确的答案，所以求助gpt后</p><p><img src="/my-blog/pics/02/image-20240218231425314.png" alt="image-20240218231425314"></p><p><img src="/my-blog/pics/02/image-20240218231502694.png" alt="image-20240218231502694"></p><p>所以最后添加useSSL=false解决问题</p>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>works</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>运维相关（生产BUG）</title>
    <link href="/my-blog/2023/11/01/%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3/"/>
    <url>/my-blog/2023/11/01/%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sql"><br>数据库备份还原<br>mysqldump <span class="hljs-operator">-</span>h192<span class="hljs-number">.168</span><span class="hljs-number">.7</span><span class="hljs-number">.55</span> <span class="hljs-operator">-</span>P13306 <span class="hljs-operator">-</span>uroot <span class="hljs-operator">-</span>p srm_prod <span class="hljs-comment">--set-gtid-purged=off &gt;/home/srm_prod20230908.sql</span><br><br>scp <span class="hljs-operator">/</span>home<span class="hljs-operator">/</span>srm_prod20230908.sql root<span class="hljs-variable">@192</span><span class="hljs-number">.168</span><span class="hljs-number">.7</span><span class="hljs-number">.52</span>:<span class="hljs-operator">/</span>home<span class="hljs-operator">/</span>srm_prod20230908.sql<br><br><br>mysql <span class="hljs-operator">-</span>uroot <span class="hljs-operator">-</span>p srm_prod20230808 <span class="hljs-operator">&lt;</span> <span class="hljs-operator">/</span>home<span class="hljs-operator">/</span>srm_prod20230908.sql<br></code></pre></td></tr></table></figure><h3 id="JS记录"><a href="#JS记录" class="headerlink" title="JS记录"></a>JS记录</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs js">去除小数点多余的<span class="hljs-number">0</span>：<span class="hljs-title function_">replace</span>(<span class="hljs-regexp">/0*$|\.0*$/</span>, <span class="hljs-string">&#x27;&#x27;</span>)<br></code></pre></td></tr></table></figure><h4 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">1、流程节点设置<br></code></pre></td></tr></table></figure><h4 id="BinLog-日志还原"><a href="#BinLog-日志还原" class="headerlink" title="BinLog 日志还原"></a>BinLog 日志还原</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sql">cd <span class="hljs-operator">/</span>opt<span class="hljs-operator">/</span>data<span class="hljs-operator">/</span>mysqldata  <span class="hljs-operator">-</span><span class="hljs-operator">&gt;</span>  对应binlog日志存放<br><br><span class="hljs-number">606082443</span><br>mysqlbinlog <span class="hljs-comment">--no-defaults -v -v --base64-output=decode-rows mysql-bin.000043 | sed -n &#x27;/# at 606082443/,/COMMIT/p&#x27; &gt; tbl_data.txt</span><br><br>[root<span class="hljs-variable">@db01</span> data]# sed <span class="hljs-string">&#x27;/WHERE/&#123;:a;N;/SET/!ba;s/\([^\n]*\)\n\(.*\)\n\(.*\)/\3\n\2\n\1/&#125;&#x27;</span> tbl_data.txt <span class="hljs-operator">|</span> sed <span class="hljs-operator">-</span>r <span class="hljs-string">&#x27;/WHERE/&#123;:a;N;/@3/!ba;s/###   @2.*//g&#125;&#x27;</span> <span class="hljs-operator">|</span> sed <span class="hljs-string">&#x27;s/### //g;s/\/\*.*/,/g&#x27;</span> <span class="hljs-operator">|</span> sed <span class="hljs-string">&#x27;/WHERE/&#123;:a;N;/@19/!ba;s/,/;/g&#125;;s/#.*//g;s/COMMIT,//g&#x27;</span> <span class="hljs-operator">|</span> sed <span class="hljs-string">&#x27;/^$/d&#x27;</span> <span class="hljs-operator">&gt;</span> recovery.sql<br>sed <span class="hljs-operator">-</span>n <span class="hljs-string">&#x27;/### UPDATE /,/### SET /p&#x27;</span> tbl_data.txt <span class="hljs-operator">|</span><br>sed <span class="hljs-operator">-</span>n <span class="hljs-string">&#x27;/@3\|@19/p&#x27;</span> <span class="hljs-operator">|</span><br>sed <span class="hljs-operator">-</span>r <span class="hljs-string">&#x27;s/.*@3=([^ ]*).*@\d+=&#x27;&#x27;\&#x27;&#x27;([^&#x27;</span>\<span class="hljs-string">&#x27;&#x27;</span>]<span class="hljs-operator">*</span>)<span class="hljs-string">&#x27;&#x27;</span>\<span class="hljs-string">&#x27;&#x27;</span>.<span class="hljs-operator">*</span><span class="hljs-operator">/</span><span class="hljs-keyword">UPDATE</span> `srm_prod`.`price_tpl_pt0075_b` <span class="hljs-keyword">set</span> os514 <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;\1&#x27;</span> <span class="hljs-keyword">WHERE</span> id <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;\2&#x27;</span><span class="hljs-operator">/</span>g<span class="hljs-string">&#x27; &gt; recovery.sql</span><br><span class="hljs-string"></span><br><span class="hljs-string">sed -n &#x27;</span><span class="hljs-operator">/</span>### <span class="hljs-keyword">UPDATE</span> <span class="hljs-operator">/</span>,<span class="hljs-operator">/</span>### <span class="hljs-keyword">SET</span> <span class="hljs-operator">/</span>p<span class="hljs-string">&#x27; tbl_data.txt |</span><br><span class="hljs-string">sed -n &#x27;</span><span class="hljs-operator">/</span><span class="hljs-variable">@3</span>\<span class="hljs-operator">|</span><span class="hljs-variable">@19</span><span class="hljs-operator">/</span>p<span class="hljs-string">&#x27; |</span><br><span class="hljs-string">sed -r &#x27;</span>s<span class="hljs-operator">/</span><span class="hljs-operator">^</span>(.<span class="hljs-operator">*</span>)<span class="hljs-variable">@3</span><span class="hljs-operator">=</span>([<span class="hljs-operator">^</span> ]<span class="hljs-operator">*</span>).<span class="hljs-operator">*</span><span class="hljs-variable">@19</span><span class="hljs-operator">=</span>\<span class="hljs-string">&#x27;\&#x27;&#x27;([^&#x27;</span>\<span class="hljs-string">&#x27;&#x27;</span>]<span class="hljs-operator">*</span>)<span class="hljs-string">&#x27;\&#x27;&#x27;.*$/\1UPDATE `\`srm_prod\`.\`price_tpl_pt0075_b\` set os514 = &#x27;</span>\<span class="hljs-number">2</span><span class="hljs-string">&#x27; WHERE id = &#x27;</span>\<span class="hljs-number">3</span><span class="hljs-string">&#x27;\\n/g&#x27;</span> <span class="hljs-operator">&gt;</span> recovery2.sql<br><br></code></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">show</span> processlist;<br>kill <span class="hljs-number">150436</span><br><span class="hljs-keyword">SHOW</span> <span class="hljs-keyword">OPEN</span> <span class="hljs-keyword">TABLES</span> <span class="hljs-keyword">where</span> In_use &gt; <span class="hljs-number">0</span>;<br><span class="hljs-keyword">SELECT</span> * <span class="hljs-keyword">FROM</span> information_schema.INNODB_TRX;<br><span class="hljs-keyword">SELECT</span> * <span class="hljs-keyword">FROM</span> INFORMATION_SCHEMA.INNODB_LOCKS;<br><br><br><span class="hljs-keyword">SELECT</span> * <span class="hljs-keyword">FROM</span> INFORMATION_SCHEMA.INNODB_LOCK_WAITS;<br></code></pre></td></tr></table></figure><h4 id="数据库备份还原"><a href="#数据库备份还原" class="headerlink" title="数据库备份还原"></a>数据库备份还原</h4><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-number">1</span> 进入数据库存放的具体位置   /var/lib/mysql/<br><span class="hljs-number">2</span> 备份   mysqldump -uroot -p 目标数据库名称 &gt; /home/bak/备份脚本名称.<span class="hljs-keyword">sql</span><br><span class="hljs-number">3</span> 跨机迁移数据 scp /home/bak/目标脚本.<span class="hljs-keyword">sql</span> root@迁移地址:/home/bak/迁移后脚本.<span class="hljs-keyword">sql</span><br><span class="hljs-number">4</span> 手动新建一个数据库<br><span class="hljs-number">5</span> 还原 mysql -uroot -p 手动新建的数据库 &lt; /home/bak/迁移后脚本.<span class="hljs-keyword">sql</span><br><span class="hljs-number">6</span> 远程连接 mysql -h <span class="hljs-number">192.168</span><span class="hljs-number">.7</span><span class="hljs-number">.55</span> -uroot -pSrm@<span class="hljs-number">8517</span> -P13306<br><br>数据库用户创建权限设置<br><span class="hljs-comment">-- 创建用户</span><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">USER</span> <span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.7.79&#x27;</span>,<span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.17.5&#x27;</span> IDENTIFIED <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;td_guest01&#x27;</span>;<br><span class="hljs-comment">-- 给表只读权限</span><br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">ON</span> srm_prod.production_return_repair <span class="hljs-keyword">TO</span> <span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.7.79&#x27;</span>,<span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.17.5&#x27;</span>;<br><span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">SELECT</span> <span class="hljs-keyword">ON</span> srm_prod.back_repair_send <span class="hljs-keyword">TO</span> <span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.7.79&#x27;</span>,<span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.17.5&#x27;</span>;<br><span class="hljs-comment">-- 刷新权限</span><br>FLUSH <span class="hljs-keyword">PRIVILEGES</span>;<br><span class="hljs-comment">-- 取回权限</span><br><span class="hljs-keyword">REVOKE</span> privilege <span class="hljs-keyword">ON</span> srm_prod20230523.back_repair_send <span class="hljs-keyword">FROM</span> <span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.17.5&#x27;</span>;<br><span class="hljs-comment">-- 查询用户</span><br><span class="hljs-keyword">select</span> <span class="hljs-keyword">distinct</span> <span class="hljs-keyword">user</span> <span class="hljs-keyword">from</span> mysql.<span class="hljs-keyword">user</span>;<br><span class="hljs-comment">-- 取回所有权限针对某个账号</span><br><span class="hljs-keyword">REVOKE</span> <span class="hljs-keyword">ALL</span> <span class="hljs-keyword">PRIVILEGES</span>, <span class="hljs-keyword">GRANT</span> <span class="hljs-keyword">OPTION</span> <span class="hljs-keyword">FROM</span> <span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.17.5&#x27;</span>;<br><span class="hljs-comment">-- 展示账号的权限</span><br><span class="hljs-keyword">SHOW</span> GRANTS <span class="hljs-keyword">FOR</span> <span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.17.5&#x27;</span>;<br><span class="hljs-comment">-- 删除用户</span><br><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">USER</span> <span class="hljs-string">&#x27;guest01&#x27;</span>@<span class="hljs-string">&#x27;192.168.7.79&#x27;</span>; <br></code></pre></td></tr></table></figure><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs stata">jdbc:mysql:<span class="hljs-comment">//192.168.7.55:13306/srm_prod?characterEncoding=UTF-8&amp;serverTimezone=UTC</span><br>root<br><br>com.zaxxer.hikari.HikariDataSource<br><br>yum install <span class="hljs-keyword">zip</span> -y<br><span class="hljs-keyword">zip</span> -r zheap0726.<span class="hljs-keyword">zip</span> zheap_localhost.localdomain_20230726150257.hprof<br>docker cp :/logs/zheap0.<span class="hljs-keyword">zip</span> /home<br><br><br>nginx<br><br>awk &#x27;&#123;<span class="hljs-keyword">split</span>(<span class="hljs-variable">$4</span>,array,<span class="hljs-string">&quot;[&quot;</span>);<span class="hljs-keyword">if</span>(array[2]&gt;=<span class="hljs-string">&quot;26/Jul/2023:16:20:05&quot;</span> &amp;&amp; array[2]&lt;=<span class="hljs-string">&quot;26/Jul/2023:16:27:05&quot;</span>)&#123;<span class="hljs-keyword">print</span> <span class="hljs-variable">$0&#125;</span>&#125;&#x27; access.<span class="hljs-keyword">log</span><br><br></code></pre></td></tr></table></figure><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-number">55</span>服务器<br>ps -ef | <span class="hljs-keyword">grep</span> activemq<br>netstat -antup | <span class="hljs-keyword">grep</span> <span class="hljs-number">61616</span> <br>firewall-cmd --zone=<span class="hljs-keyword">public</span> --add-port=<span class="hljs-number">8161</span>/tcp --permanent<br>firewall-cmd --zone=<span class="hljs-keyword">public</span> --add-port=<span class="hljs-number">61616</span>/tcp --permanent<br><span class="hljs-regexp">/root/</span>activeMQ<span class="hljs-regexp">/apache-activemq-5.14.5/</span>bin<br>./activemq start<br><br>挂载nfs<br><span class="hljs-number">54</span> <span class="hljs-number">53</span>分别挂载到<span class="hljs-number">55</span><br>mount -t nfs <span class="hljs-number">192.168</span>.<span class="hljs-number">7.55</span>:<span class="hljs-regexp">/nfsshare /</span>app<span class="hljs-regexp">/tsrm/</span>jenkinsPackage<br><br></code></pre></td></tr></table></figure><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs vim">服务器停机处理<br>分别进入srm前端、sip前端容器  docker exec -it xxx <span class="hljs-keyword">sh</span><br><span class="hljs-keyword">cd</span> /etc/nginx/<span class="hljs-keyword">conf</span>.d<br><span class="hljs-keyword">vi</span> default.xxx   修改location地址为对应的后端地址  保存后 nginx -s reload <br></code></pre></td></tr></table></figure><h4 id="CPU飙升排查"><a href="#CPU飙升排查" class="headerlink" title="CPU飙升排查"></a>CPU飙升排查</h4><p>top -H -p 9  查看CPU占用高的具体线程，发现耗CPU的线程都是比较小的PID，根据经验可知应该是GC的问题</p><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/image-20230605135218278.png" alt="image-20230605135218278"></p><h4 id="jmap-histo-9-head-20-前20堆栈查看有没有明显错误"><a href="#jmap-histo-9-head-20-前20堆栈查看有没有明显错误" class="headerlink" title="jmap -histo 9 | head -20  前20堆栈查看有没有明显错误"></a>jmap -histo 9 | head -20  前20堆栈查看有没有明显错误</h4><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/image-20230605135357623.png" alt="image-20230605135357623"></p><h4 id="jmap-heap-9-查看gc情况"><a href="#jmap-heap-9-查看gc情况" class="headerlink" title="jmap -heap 9 查看gc情况"></a>jmap -heap 9 查看gc情况</h4><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/image-20230605135423240.png" alt="image-20230605135423240"></p><h5 id="下载dump日志进一步分析"><a href="#下载dump日志进一步分析" class="headerlink" title="下载dump日志进一步分析"></a>下载dump日志进一步分析</h5><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arcade">jmap -dump:format=b,file=<span class="hljs-regexp">/logs/</span>zheap_$(hostname)_$(<span class="hljs-built_in">date</span> +<span class="hljs-string">&quot;%Y%m%d%H%M%S&quot;</span>).hprof <span class="hljs-number">9</span><br>jstack -F -m <span class="hljs-number">9</span> &gt;&gt; <span class="hljs-regexp">/logs/</span>zjstack_$(hostname)_$(<span class="hljs-built_in">date</span> +<span class="hljs-string">&quot;%Y%m%d%H%M%S&quot;</span>).<span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure><h5 id="分析结果"><a href="#分析结果" class="headerlink" title="分析结果"></a>分析结果</h5><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16859459636069.png" alt="img"></p><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16859470992276.png" alt="img"></p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16859470879029.png" alt="img" style="zoom: 50%;" /><p>判断是由于用户使用了合同明细的导出功能导致GC异常从而导致CPU飙升至1000%</p><h3 id="CPU飙升排查2"><a href="#CPU飙升排查2" class="headerlink" title="CPU飙升排查2"></a>CPU飙升排查2</h3><h5 id="下载dump日志进行分析"><a href="#下载dump日志进行分析" class="headerlink" title="下载dump日志进行分析"></a>下载dump日志进行分析</h5><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/image-20230616110747670.png" alt="image-20230616110747670"></p><p>发现问题出现在groovy代码块中，继续排查</p><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/image-20230616110940883.png" alt="image-20230616110940883"></p><p>发现与订单的查询sql语句有关，继续排查</p><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_16868828363055.png" alt="img"></p><p>找到具体代码块6D5E578AA665F1518A6C，确认是新增/编辑单个入库单接口前-校验入库单信息代码块的问题</p><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/image-20230616111434032.png" alt="image-20230616111434032"></p><p>增加判空处理</p><h3 id="CPU飙升排查3"><a href="#CPU飙升排查3" class="headerlink" title="CPU飙升排查3"></a>CPU飙升排查3</h3><p>下载dump日志分析</p><p><img src="https://gilimall-xae.oss-cn-hangzhou.aliyuncs.com/blog_typora/image-20230703161800596.png" alt="image-20230703161800596"></p><p>结合实际操作情况判断是订单报表导出导致的CPU飙升宕机</p>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>works</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
